{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45fc72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuración inicial y carga de paquetes\n",
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91528f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: lib_lightgbm found in system dirs!\n",
      "└ @ LightGBM C:\\Users\\natal\\.julia\\packages\\LightGBM\\xQZ0z\\src\\LightGBM.jl:32\n"
     ]
    }
   ],
   "source": [
    "using MLJ, DataFrames, Statistics, Random\n",
    "using CSV, Dates, CategoricalArrays\n",
    "using MLJLinearModels, DecisionTree, NearestNeighborModels, LightGBM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7882cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pkg> instantiate\n",
    "#pkg> update\n",
    "#pkg> build SpecialFunctions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d51bdd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "#Pkg.status([\"MLJ\", \"DecisionTree\", \"MLJBase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac8557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pkg.add(\"EvoTrees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2730c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "using EvoTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c094c556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The number and/or types of data arguments do not match what the specified model\n",
      "│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "│ \n",
      "│ Run `@doc EvoTrees.EvoTreeRegressor` to learn more about your model's requirements.\n",
      "│ \n",
      "│ Commonly, but non exclusively, supervised models are constructed using the syntax\n",
      "│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "│ sample or class weights.\n",
      "│ \n",
      "│ In general, data in `machine(model, data...)` is expected to satisfy\n",
      "│ \n",
      "│     scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "│ \n",
      "│ In the present case:\n",
      "│ \n",
      "│ scitype(data) = Tuple{Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}, AbstractVector{Count}}\n",
      "│ \n",
      "│ fit_data_scitype(model) = Union{Tuple{Union{Table{<:Union{AbstractVector{<:Continuous}, AbstractVector{<:Count}, AbstractVector{<:OrderedFactor}, AbstractVector{<:Multiclass}}}, AbstractMatrix{Continuous}}, AbstractVector{<:Continuous}}, Tuple{Union{Table{<:Union{AbstractVector{<:Continuous}, AbstractVector{<:Count}, AbstractVector{<:OrderedFactor}, AbstractVector{<:Multiclass}}}, AbstractMatrix{Continuous}}, AbstractVector{<:Continuous}, AbstractVector{<:Union{Continuous, Count}}}}\n",
      "└ @ MLJBase C:\\Users\\natal\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:237\n",
      "┌ Warning: The number and/or types of data arguments do not match what the specified model\n",
      "│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "│ \n",
      "│ Run `@doc MLJLinearModels.RidgeRegressor` to learn more about your model's requirements.\n",
      "│ \n",
      "│ Commonly, but non exclusively, supervised models are constructed using the syntax\n",
      "│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "│ sample or class weights.\n",
      "│ \n",
      "│ In general, data in `machine(model, data...)` is expected to satisfy\n",
      "│ \n",
      "│     scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "│ \n",
      "│ In the present case:\n",
      "│ \n",
      "│ scitype(data) = Tuple{Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}, AbstractVector{Count}}\n",
      "│ \n",
      "│ fit_data_scitype(model) = Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}\n",
      "└ @ MLJBase C:\\Users\\natal\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:237\n",
      "┌ Warning: The number and/or types of data arguments do not match what the specified model\n",
      "│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "│ \n",
      "│ Run `@doc NearestNeighborModels.KNNRegressor` to learn more about your model's requirements.\n",
      "│ \n",
      "│ Commonly, but non exclusively, supervised models are constructed using the syntax\n",
      "│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "│ sample or class weights.\n",
      "│ \n",
      "│ In general, data in `machine(model, data...)` is expected to satisfy\n",
      "│ \n",
      "│     scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "│ \n",
      "│ In the present case:\n",
      "│ \n",
      "│ scitype(data) = Tuple{Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}, AbstractVector{Count}}\n",
      "│ \n",
      "│ fit_data_scitype(model) = Union{Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}, Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}, AbstractVector{<:Union{Continuous, Count}}}}\n",
      "└ @ MLJBase C:\\Users\\natal\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:237\n",
      "┌ Warning: The number and/or types of data arguments do not match what the specified model\n",
      "│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "│ \n",
      "│ Run `@doc MLJLinearModels.LassoRegressor` to learn more about your model's requirements.\n",
      "│ \n",
      "│ Commonly, but non exclusively, supervised models are constructed using the syntax\n",
      "│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "│ sample or class weights.\n",
      "│ \n",
      "│ In general, data in `machine(model, data...)` is expected to satisfy\n",
      "│ \n",
      "│     scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "│ \n",
      "│ In the present case:\n",
      "│ \n",
      "│ scitype(data) = Tuple{Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}, AbstractVector{Count}}\n",
      "│ \n",
      "│ fit_data_scitype(model) = Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}\n",
      "└ @ MLJBase C:\\Users\\natal\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:237\n",
      "┌ Warning: No appropriate stepsize found via backtracking; interrupting. The reason could be input data that is not standardized.\n",
      "└ @ MLJLinearModels C:\\Users\\natal\\.julia\\packages\\MLJLinearModels\\s9vSj\\src\\fit\\proxgrad.jl:59\n",
      "┌ Warning: Proximal GD did not converge in 1000 iterations.\n",
      "└ @ MLJLinearModels C:\\Users\\natal\\.julia\\packages\\MLJLinearModels\\s9vSj\\src\\fit\\proxgrad.jl:73\n",
      "┌ Warning: The number and/or types of data arguments do not match what the specified model\n",
      "│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "│ \n",
      "│ Run `@doc MLJLinearModels.RidgeRegressor` to learn more about your model's requirements.\n",
      "│ \n",
      "│ Commonly, but non exclusively, supervised models are constructed using the syntax\n",
      "│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "│ sample or class weights.\n",
      "│ \n",
      "│ In general, data in `machine(model, data...)` is expected to satisfy\n",
      "│ \n",
      "│     scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "│ \n",
      "│ In the present case:\n",
      "│ \n",
      "│ scitype(data) = Tuple{Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}, AbstractVector{Count}}\n",
      "│ \n",
      "│ fit_data_scitype(model) = Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}\n",
      "└ @ MLJBase C:\\Users\\natal\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:237\n",
      "┌ Warning: The number and/or types of data arguments do not match what the specified model\n",
      "│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "│ \n",
      "│ Run `@doc NearestNeighborModels.KNNRegressor` to learn more about your model's requirements.\n",
      "│ \n",
      "│ Commonly, but non exclusively, supervised models are constructed using the syntax\n",
      "│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "│ sample or class weights.\n",
      "│ \n",
      "│ In general, data in `machine(model, data...)` is expected to satisfy\n",
      "│ \n",
      "│     scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "│ \n",
      "│ In the present case:\n",
      "│ \n",
      "│ scitype(data) = Tuple{Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}, AbstractVector{Count}}\n",
      "│ \n",
      "│ fit_data_scitype(model) = Union{Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}, Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}, AbstractVector{<:Union{Continuous, Count}}}}\n",
      "└ @ MLJBase C:\\Users\\natal\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:237\n",
      "┌ Warning: The number and/or types of data arguments do not match what the specified model\n",
      "│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "│ \n",
      "│ Run `@doc MLJLinearModels.LassoRegressor` to learn more about your model's requirements.\n",
      "│ \n",
      "│ Commonly, but non exclusively, supervised models are constructed using the syntax\n",
      "│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "│ sample or class weights.\n",
      "│ \n",
      "│ In general, data in `machine(model, data...)` is expected to satisfy\n",
      "│ \n",
      "│     scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "│ \n",
      "│ In the present case:\n",
      "│ \n",
      "│ scitype(data) = Tuple{Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}, AbstractVector{Count}}\n",
      "│ \n",
      "│ fit_data_scitype(model) = Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}\n",
      "└ @ MLJBase C:\\Users\\natal\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:237\n",
      "┌ Warning: No appropriate stepsize found via backtracking; interrupting. The reason could be input data that is not standardized.\n",
      "└ @ MLJLinearModels C:\\Users\\natal\\.julia\\packages\\MLJLinearModels\\s9vSj\\src\\fit\\proxgrad.jl:59\n",
      "┌ Warning: Proximal GD did not converge in 1000 iterations.\n",
      "└ @ MLJLinearModels C:\\Users\\natal\\.julia\\packages\\MLJLinearModels\\s9vSj\\src\\fit\\proxgrad.jl:73\n",
      "┌ Warning: The number and/or types of data arguments do not match what the specified model\n",
      "│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "│ \n",
      "│ Run `@doc NearestNeighborModels.KNNRegressor` to learn more about your model's requirements.\n",
      "│ \n",
      "│ Commonly, but non exclusively, supervised models are constructed using the syntax\n",
      "│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "│ sample or class weights.\n",
      "│ \n",
      "│ In general, data in `machine(model, data...)` is expected to satisfy\n",
      "│ \n",
      "│     scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "│ \n",
      "│ In the present case:\n",
      "│ \n",
      "│ scitype(data) = Tuple{Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}, AbstractVector{Count}}\n",
      "│ \n",
      "│ fit_data_scitype(model) = Union{Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}, Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}, AbstractVector{<:Union{Continuous, Count}}}}\n",
      "└ @ MLJBase C:\\Users\\natal\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:237\n",
      "┌ Warning: The number and/or types of data arguments do not match what the specified model\n",
      "│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "│ \n",
      "│ Run `@doc EvoTrees.EvoTreeRegressor` to learn more about your model's requirements.\n",
      "│ \n",
      "│ Commonly, but non exclusively, supervised models are constructed using the syntax\n",
      "│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "│ sample or class weights.\n",
      "│ \n",
      "│ In general, data in `machine(model, data...)` is expected to satisfy\n",
      "│ \n",
      "│     scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "│ \n",
      "│ In the present case:\n",
      "│ \n",
      "│ scitype(data) = Tuple{Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}, AbstractVector{Count}}\n",
      "│ \n",
      "│ fit_data_scitype(model) = Union{Tuple{Union{Table{<:Union{AbstractVector{<:Continuous}, AbstractVector{<:Count}, AbstractVector{<:OrderedFactor}, AbstractVector{<:Multiclass}}}, AbstractMatrix{Continuous}}, AbstractVector{<:Continuous}}, Tuple{Union{Table{<:Union{AbstractVector{<:Continuous}, AbstractVector{<:Count}, AbstractVector{<:OrderedFactor}, AbstractVector{<:Multiclass}}}, AbstractMatrix{Continuous}}, AbstractVector{<:Continuous}, AbstractVector{<:Union{Continuous, Count}}}}\n",
      "└ @ MLJBase C:\\Users\\natal\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:237\n",
      "┌ Warning: The number and/or types of data arguments do not match what the specified model\n",
      "│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "│ \n",
      "│ Run `@doc MLJLinearModels.LinearRegressor` to learn more about your model's requirements.\n",
      "│ \n",
      "│ Commonly, but non exclusively, supervised models are constructed using the syntax\n",
      "│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "│ sample or class weights.\n",
      "│ \n",
      "│ In general, data in `machine(model, data...)` is expected to satisfy\n",
      "│ \n",
      "│     scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "│ \n",
      "│ In the present case:\n",
      "│ \n",
      "│ scitype(data) = Tuple{Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}, AbstractVector{Count}}\n",
      "│ \n",
      "│ fit_data_scitype(model) = Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}\n",
      "└ @ MLJBase C:\\Users\\natal\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:237\n",
      "┌ Warning: The number and/or types of data arguments do not match what the specified model\n",
      "│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "│ \n",
      "│ Run `@doc NearestNeighborModels.KNNRegressor` to learn more about your model's requirements.\n",
      "│ \n",
      "│ Commonly, but non exclusively, supervised models are constructed using the syntax\n",
      "│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "│ sample or class weights.\n",
      "│ \n",
      "│ In general, data in `machine(model, data...)` is expected to satisfy\n",
      "│ \n",
      "│     scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "│ \n",
      "│ In the present case:\n",
      "│ \n",
      "│ scitype(data) = Tuple{Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}, AbstractVector{Count}}\n",
      "│ \n",
      "│ fit_data_scitype(model) = Union{Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}, Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}, AbstractVector{<:Union{Continuous, Count}}}}\n",
      "└ @ MLJBase C:\\Users\\natal\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:237\n",
      "┌ Warning: The number and/or types of data arguments do not match what the specified model\n",
      "│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "│ \n",
      "│ Run `@doc EvoTrees.EvoTreeRegressor` to learn more about your model's requirements.\n",
      "│ \n",
      "│ Commonly, but non exclusively, supervised models are constructed using the syntax\n",
      "│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "│ sample or class weights.\n",
      "│ \n",
      "│ In general, data in `machine(model, data...)` is expected to satisfy\n",
      "│ \n",
      "│     scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "│ \n",
      "│ In the present case:\n",
      "│ \n",
      "│ scitype(data) = Tuple{Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}, AbstractVector{Count}}\n",
      "│ \n",
      "│ fit_data_scitype(model) = Union{Tuple{Union{Table{<:Union{AbstractVector{<:Continuous}, AbstractVector{<:Count}, AbstractVector{<:OrderedFactor}, AbstractVector{<:Multiclass}}}, AbstractMatrix{Continuous}}, AbstractVector{<:Continuous}}, Tuple{Union{Table{<:Union{AbstractVector{<:Continuous}, AbstractVector{<:Count}, AbstractVector{<:OrderedFactor}, AbstractVector{<:Multiclass}}}, AbstractMatrix{Continuous}}, AbstractVector{<:Continuous}, AbstractVector{<:Union{Continuous, Count}}}}\n",
      "└ @ MLJBase C:\\Users\\natal\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:237\n",
      "┌ Warning: The number and/or types of data arguments do not match what the specified model\n",
      "│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "│ \n",
      "│ Run `@doc MLJLinearModels.RidgeRegressor` to learn more about your model's requirements.\n",
      "│ \n",
      "│ Commonly, but non exclusively, supervised models are constructed using the syntax\n",
      "│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "│ sample or class weights.\n",
      "│ \n",
      "│ In general, data in `machine(model, data...)` is expected to satisfy\n",
      "│ \n",
      "│     scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "│ \n",
      "│ In the present case:\n",
      "│ \n",
      "│ scitype(data) = Tuple{Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}, AbstractVector{Count}}\n",
      "│ \n",
      "│ fit_data_scitype(model) = Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}\n",
      "└ @ MLJBase C:\\Users\\natal\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:237\n",
      "┌ Warning: The number and/or types of data arguments do not match what the specified model\n",
      "│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "│ \n",
      "│ Run `@doc MLJLinearModels.LassoRegressor` to learn more about your model's requirements.\n",
      "│ \n",
      "│ Commonly, but non exclusively, supervised models are constructed using the syntax\n",
      "│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "│ sample or class weights.\n",
      "│ \n",
      "│ In general, data in `machine(model, data...)` is expected to satisfy\n",
      "│ \n",
      "│     scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "│ \n",
      "│ In the present case:\n",
      "│ \n",
      "│ scitype(data) = Tuple{Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}, AbstractVector{Count}}\n",
      "│ \n",
      "│ fit_data_scitype(model) = Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}\n",
      "└ @ MLJBase C:\\Users\\natal\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:237\n",
      "┌ Warning: No appropriate stepsize found via backtracking; interrupting. The reason could be input data that is not standardized.\n",
      "└ @ MLJLinearModels C:\\Users\\natal\\.julia\\packages\\MLJLinearModels\\s9vSj\\src\\fit\\proxgrad.jl:59\n",
      "┌ Warning: Proximal GD did not converge in 1000 iterations.\n",
      "└ @ MLJLinearModels C:\\Users\\natal\\.julia\\packages\\MLJLinearModels\\s9vSj\\src\\fit\\proxgrad.jl:73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 195\n",
      "[LightGBM] [Info] Number of data points in the train set: 276500, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 1.228510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The number and/or types of data arguments do not match what the specified model\n",
      "│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "│ \n",
      "│ Run `@doc LightGBM.LGBMRegressor` to learn more about your model's requirements.\n",
      "│ \n",
      "│ Commonly, but non exclusively, supervised models are constructed using the syntax\n",
      "│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "│ sample or class weights.\n",
      "│ \n",
      "│ In general, data in `machine(model, data...)` is expected to satisfy\n",
      "│ \n",
      "│     scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "│ \n",
      "│ In the present case:\n",
      "│ \n",
      "│ scitype(data) = Tuple{Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}, AbstractVector{Count}}\n",
      "│ \n",
      "│ fit_data_scitype(model) = Union{Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}, Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}, AbstractVector{<:Union{Continuous, Count}}}}\n",
      "└ @ MLJBase C:\\Users\\natal\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:237\n",
      "┌ Warning: The number and/or types of data arguments do not match what the specified model\n",
      "│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "│ \n",
      "│ Run `@doc NearestNeighborModels.KNNRegressor` to learn more about your model's requirements.\n",
      "│ \n",
      "│ Commonly, but non exclusively, supervised models are constructed using the syntax\n",
      "│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "│ sample or class weights.\n",
      "│ \n",
      "│ In general, data in `machine(model, data...)` is expected to satisfy\n",
      "│ \n",
      "│     scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "│ \n",
      "│ In the present case:\n",
      "│ \n",
      "│ scitype(data) = Tuple{Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}, AbstractVector{Count}}\n",
      "│ \n",
      "│ fit_data_scitype(model) = Union{Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}, Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}, AbstractVector{<:Union{Continuous, Count}}}}\n",
      "└ @ MLJBase C:\\Users\\natal\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:237\n",
      "┌ Warning: The number and/or types of data arguments do not match what the specified model\n",
      "│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "│ \n",
      "│ Run `@doc LightGBM.LGBMRegressor` to learn more about your model's requirements.\n",
      "│ \n",
      "│ Commonly, but non exclusively, supervised models are constructed using the syntax\n",
      "│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "│ sample or class weights.\n",
      "│ \n",
      "│ In general, data in `machine(model, data...)` is expected to satisfy\n",
      "│ \n",
      "│     scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "│ \n",
      "│ In the present case:\n",
      "│ \n",
      "│ scitype(data) = Tuple{Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}, AbstractVector{Count}}\n",
      "│ \n",
      "│ fit_data_scitype(model) = Union{Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}, Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}, AbstractVector{<:Union{Continuous, Count}}}}\n",
      "└ @ MLJBase C:\\Users\\natal\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195\n",
      "[LightGBM] [Info] Number of data points in the train set: 276500, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 1.228510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The number and/or types of data arguments do not match what the specified model\n",
      "│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "│ \n",
      "│ Run `@doc LightGBM.LGBMRegressor` to learn more about your model's requirements.\n",
      "│ \n",
      "│ Commonly, but non exclusively, supervised models are constructed using the syntax\n",
      "│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "│ sample or class weights.\n",
      "│ \n",
      "│ In general, data in `machine(model, data...)` is expected to satisfy\n",
      "│ \n",
      "│     scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "│ \n",
      "│ In the present case:\n",
      "│ \n",
      "│ scitype(data) = Tuple{Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}, AbstractVector{Count}}\n",
      "│ \n",
      "│ fit_data_scitype(model) = Union{Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}, Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}, AbstractVector{<:Union{Continuous, Count}}}}\n",
      "└ @ MLJBase C:\\Users\\natal\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195\n",
      "[LightGBM] [Info] Number of data points in the train set: 276500, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 1.228510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(data_summary = (total_rows = 395000,\n",
       "                 features = 7,\n",
       "                 train_size = 276500,\n",
       "                 test_size = 118500,\n",
       "                 feature_names = [\"product_identifier\", \"department_identifier\", \"outlet\", \"sell_price\", \"Month\", \"state_encoded\", \"category_encoded\"],),\n",
       " ranking = \u001b[1m18×6 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Model            \u001b[0m\u001b[1m MAE     \u001b[0m\u001b[1m MSE      \u001b[0m\u001b[1m RMSE    \u001b[0m\u001b[1m R2         \u001b[0m\u001b[1m Training_Time\u001b[0m ⋯\n",
       "     │\u001b[90m String           \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64      \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ LGBM_Default      1.10681   8.11152  2.84807   0.377788       1.609     ⋯\n",
       "   2 │ KNN_35            1.07139   8.16223  2.85696   0.373898       0.199\n",
       "   3 │ EvoTree_200       1.10103   8.16419  2.8573    0.373748       3.879\n",
       "   4 │ EvoTree_100       1.12776   8.29465  2.88004   0.36374        2.23\n",
       "   5 │ KNN_25            1.06201   8.31114  2.88291   0.362475       0.183     ⋯\n",
       "   6 │ LGBM_200          1.19327   8.41529  2.90091   0.354486       4.729\n",
       "   7 │ KNN_15            1.06371   8.45142  2.90713   0.351714       0.396\n",
       "   8 │ EvoTree_50        1.16948   8.48419  2.91276   0.349201       2.345\n",
       "  ⋮  │        ⋮             ⋮        ⋮         ⋮         ⋮             ⋮       ⋱\n",
       "  12 │ LinearRegression  1.55047  12.1856   3.49078   0.0652779      0.151     ⋯\n",
       "  13 │ Ridge_0.1         1.56339  12.266    3.50228   0.0591103      0.177\n",
       "  14 │ Ridge_1.0         1.55978  12.2725   3.50322   0.0586084      0.0220001\n",
       "  15 │ Ridge_10.0        1.54542  12.3487   3.51407   0.0527661      0.0340002\n",
       "  16 │ Lasso_10.0        1.22987  14.5492   3.81434  -0.116027       2.272     ⋯\n",
       "  17 │ Lasso_0.1         1.22987  14.5492   3.81434  -0.116027       1.034\n",
       "  18 │ Lasso_1.0         1.22987  14.5492   3.81434  -0.116027       1.059\n",
       "\u001b[36m                                                                 3 rows omitted\u001b[0m,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CÓDIGO COMPLETO FINAL - Con encoding de variables categóricas\n",
    "using MLJ, DataFrames, CSV, Statistics, Dates, Random, CategoricalArrays\n",
    "using MLJ: @load, machine, fit!, predict\n",
    "using EvoTrees\n",
    "using LightGBM \n",
    "import LightGBM.MLJInterface: LGBMRegressor  # define the regressor type directly\n",
    "\n",
    "# ========================================\n",
    "# 1. CARGA Y PROCESAMIENTO DE DATOS\n",
    "# ========================================\n",
    "\n",
    "# Cargar datos desde carpeta dataO\n",
    "df_train = DataFrame(CSV.File(\"dataO/train_data.csv\"))\n",
    "df_week = DataFrame(CSV.File(\"dataO/date_to_week_id_map.csv\"))\n",
    "df_prices = DataFrame(CSV.File(\"dataO/product_prices.csv\"))\n",
    "\n",
    "# Realizar joins\n",
    "df = innerjoin(df_prices, df_week, on = :week_id)\n",
    "df_final = innerjoin(df_train, df, on = [:date, :product_identifier, :outlet])\n",
    "\n",
    "# Preparar features con encoding de variables categóricas\n",
    "using CategoricalArrays\n",
    "\n",
    "# Convertir a categóricas\n",
    "df_final.category_of_product = categorical(df_final.category_of_product)\n",
    "df_final.state = categorical(df_final.state)\n",
    "\n",
    "# Crear encodings\n",
    "df_final.state_encoded = levelcode.(df_final.state)\n",
    "df_final.category_encoded = levelcode.(df_final.category_of_product)\n",
    "df_final.Month = month.(df_final.date)\n",
    "\n",
    "# Seleccionar features incluyendo las variables categóricas encodificadas\n",
    "X = select(df_final, [:product_identifier, :department_identifier, :outlet, \n",
    "                      :sell_price, :Month, :state_encoded, :category_encoded])\n",
    "y = df_final.sales\n",
    "\n",
    "# División train/test reproducible (70/30)\n",
    "Random.seed!(42)\n",
    "n = nrow(X)\n",
    "train_size = floor(Int, 0.7 * n)\n",
    "perm = randperm(n)\n",
    "\n",
    "X_train = X[perm[1:train_size], :]\n",
    "X_test = X[perm[train_size+1:end], :]\n",
    "y_train = y[perm[1:train_size]]\n",
    "y_test = y[perm[train_size+1:end]]\n",
    "\n",
    "\n",
    "# Verificar dimensiones de los datos\n",
    "data_summary = (\n",
    "    total_rows = nrow(df_final),\n",
    "    features = ncol(X),\n",
    "    train_size = nrow(X_train),\n",
    "    test_size = nrow(X_test),\n",
    "    feature_names = names(X)\n",
    ")\n",
    "\n",
    "# ========================================\n",
    "# 2. CARGA DE MODELOS\n",
    "# ========================================\n",
    "\n",
    "# Cargar todos los modelos funcionales\n",
    "@load LinearRegressor pkg=MLJLinearModels verbosity=0\n",
    "@load RidgeRegressor pkg=MLJLinearModels verbosity=0\n",
    "@load LassoRegressor pkg=MLJLinearModels verbosity=0\n",
    "@load KNNRegressor pkg=NearestNeighborModels verbosity=0\n",
    "@load EvoTreeRegressor pkg=EvoTrees verbosity=0\n",
    "#Nuevo\n",
    "@load LGBMRegressor        pkg=LightGBM verbosity=0\n",
    "\n",
    "# ========================================\n",
    "# 3. DEFINICIÓN DE MODELOS\n",
    "# ========================================\n",
    "\n",
    "# Arsenal completo de modelos con diferentes configuraciones\n",
    "all_models = Dict(\n",
    "    # Modelos lineales\n",
    "    \"LinearRegression\" => LinearRegressor(),\n",
    "    \"Ridge_0.1\" => RidgeRegressor(lambda=0.1),\n",
    "    \"Ridge_1.0\" => RidgeRegressor(lambda=1.0),\n",
    "    \"Ridge_10.0\" => RidgeRegressor(lambda=10.0),\n",
    "    \"Lasso_0.1\" => LassoRegressor(lambda=0.1),\n",
    "    \"Lasso_1.0\" => LassoRegressor(lambda=1.0),\n",
    "    \"Lasso_10.0\" => LassoRegressor(lambda=10.0),\n",
    "    \n",
    "    # K-Nearest Neighbors\n",
    "    \"KNN_5\" => KNNRegressor(K=5),\n",
    "    \"KNN_10\" => KNNRegressor(K=10),\n",
    "    \"KNN_15\" => KNNRegressor(K=15),\n",
    "    \"KNN_25\" => KNNRegressor(K=25),\n",
    "    \"KNN_35\" => KNNRegressor(K=35),\n",
    "    \n",
    "    # Evolutionary Trees (Gradient Boosting)\n",
    "    \"EvoTree_50\" => EvoTreeRegressor(nrounds=50),\n",
    "    \"EvoTree_100\" => EvoTreeRegressor(nrounds=100),\n",
    "    \"EvoTree_200\" => EvoTreeRegressor(nrounds=200),\n",
    "\n",
    "\n",
    "    #Nuevo - LightGBM\n",
    "    \"LGBM_Default\"     => LGBMRegressor(),\n",
    "    \"LGBM_100\"         => LGBMRegressor(num_iterations=100, learning_rate=0.1, num_leaves=31),\n",
    "    \"LGBM_200\"         => LGBMRegressor(num_iterations=200, learning_rate=0.05, num_leaves=50)\n",
    ")\n",
    "\n",
    "# ========================================\n",
    "# 4. ENTRENAMIENTO Y EVALUACIÓN\n",
    "# ========================================\n",
    "\n",
    "# DataFrame para almacenar resultados\n",
    "ultimate_results = DataFrame(\n",
    "    Model = String[],\n",
    "    MAE = Float64[],\n",
    "    MSE = Float64[],\n",
    "    RMSE = Float64[],\n",
    "    R2 = Float64[],\n",
    "    Training_Time = Float64[]\n",
    ")\n",
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "for (name, model) in all_models\n",
    "    start_time = time()\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    mach = machine(model, X_train, y_train)\n",
    "    fit!(mach, verbosity=0)\n",
    "    \n",
    "    training_time = time() - start_time\n",
    "    \n",
    "    # Realizar predicciones\n",
    "    ŷ = predict(mach, X_test)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    mae_val = mean(abs.(ŷ .- y_test))\n",
    "    mse_val = mean((ŷ .- y_test).^2)\n",
    "    rmse_val = sqrt(mse_val)\n",
    "    r2_val = 1 - sum((y_test .- ŷ).^2) / sum((y_test .- mean(y_test)).^2)\n",
    "    \n",
    "    # Agregar resultados\n",
    "    push!(ultimate_results, (name, mae_val, mse_val, rmse_val, r2_val, training_time))\n",
    "end\n",
    "\n",
    "# ========================================\n",
    "# 5. RESULTADOS FINALES\n",
    "# ========================================\n",
    "\n",
    "# Ordenar por RMSE (menor es mejor)\n",
    "final_ranking = sort(ultimate_results, :RMSE)\n",
    "\n",
    "# Mostrar resumen de datos y ranking final\n",
    "(data_summary = data_summary, ranking = final_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8261ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>395000×7 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">394975 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">product_identifier</th><th style = \"text-align: left;\">department_identifier</th><th style = \"text-align: left;\">outlet</th><th style = \"text-align: left;\">sell_price</th><th style = \"text-align: left;\">Month</th><th style = \"text-align: left;\">state_encoded</th><th style = \"text-align: left;\">category_encoded</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">74</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">111</td><td style = \"text-align: right;\">2.94</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">3</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">74</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">111</td><td style = \"text-align: right;\">2.94</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">3</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">74</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">111</td><td style = \"text-align: right;\">2.94</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">3</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">74</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">111</td><td style = \"text-align: right;\">2.94</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">3</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">74</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">111</td><td style = \"text-align: right;\">2.94</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">3</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">74</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">111</td><td style = \"text-align: right;\">2.94</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">3</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">74</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">111</td><td style = \"text-align: right;\">2.94</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">3</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">74</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">111</td><td style = \"text-align: right;\">2.94</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">3</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">74</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">111</td><td style = \"text-align: right;\">2.94</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">3</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">74</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">111</td><td style = \"text-align: right;\">2.94</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">3</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">74</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">111</td><td style = \"text-align: right;\">2.94</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">3</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">74</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">111</td><td style = \"text-align: right;\">2.94</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">3</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">74</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">111</td><td style = \"text-align: right;\">2.94</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">3</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">394989</td><td style = \"text-align: right;\">3021</td><td style = \"text-align: right;\">33</td><td style = \"text-align: right;\">333</td><td style = \"text-align: right;\">2.08</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">394990</td><td style = \"text-align: right;\">3021</td><td style = \"text-align: right;\">33</td><td style = \"text-align: right;\">333</td><td style = \"text-align: right;\">2.08</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">394991</td><td style = \"text-align: right;\">3021</td><td style = \"text-align: right;\">33</td><td style = \"text-align: right;\">333</td><td style = \"text-align: right;\">2.08</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">394992</td><td style = \"text-align: right;\">3021</td><td style = \"text-align: right;\">33</td><td style = \"text-align: right;\">333</td><td style = \"text-align: right;\">2.08</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">394993</td><td style = \"text-align: right;\">3021</td><td style = \"text-align: right;\">33</td><td style = \"text-align: right;\">333</td><td style = \"text-align: right;\">2.08</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">394994</td><td style = \"text-align: right;\">3021</td><td style = \"text-align: right;\">33</td><td style = \"text-align: right;\">333</td><td style = \"text-align: right;\">2.08</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">394995</td><td style = \"text-align: right;\">3021</td><td style = \"text-align: right;\">33</td><td style = \"text-align: right;\">333</td><td style = \"text-align: right;\">2.08</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">394996</td><td style = \"text-align: right;\">3021</td><td style = \"text-align: right;\">33</td><td style = \"text-align: right;\">333</td><td style = \"text-align: right;\">2.08</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">394997</td><td style = \"text-align: right;\">3021</td><td style = \"text-align: right;\">33</td><td style = \"text-align: right;\">333</td><td style = \"text-align: right;\">2.08</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">394998</td><td style = \"text-align: right;\">3021</td><td style = \"text-align: right;\">33</td><td style = \"text-align: right;\">333</td><td style = \"text-align: right;\">2.08</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">394999</td><td style = \"text-align: right;\">3021</td><td style = \"text-align: right;\">33</td><td style = \"text-align: right;\">333</td><td style = \"text-align: right;\">2.08</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">395000</td><td style = \"text-align: right;\">3021</td><td style = \"text-align: right;\">33</td><td style = \"text-align: right;\">333</td><td style = \"text-align: right;\">2.08</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& product\\_identifier & department\\_identifier & outlet & sell\\_price & Month & state\\_encoded & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Float64 & Int64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t2 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t3 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t4 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t5 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t6 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t7 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t8 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t9 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t10 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t11 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t12 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t13 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t14 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t15 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t16 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t17 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t18 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t19 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t20 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t21 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t22 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t23 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t24 & 74 & 11 & 111 & 2.94 & 1 & 2 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m395000×7 DataFrame\u001b[0m\n",
       "\u001b[1m    Row \u001b[0m│\u001b[1m product_identifier \u001b[0m\u001b[1m department_identifier \u001b[0m\u001b[1m outlet \u001b[0m\u001b[1m sell_price \u001b[0m\u001b[1m Month\u001b[0m ⋯\n",
       "        │\u001b[90m Int64              \u001b[0m\u001b[90m Int64                 \u001b[0m\u001b[90m Int64  \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Int64\u001b[0m ⋯\n",
       "────────┼───────────────────────────────────────────────────────────────────────\n",
       "      1 │                 74                     11     111        2.94      1 ⋯\n",
       "      2 │                 74                     11     111        2.94      1\n",
       "      3 │                 74                     11     111        2.94      1\n",
       "      4 │                 74                     11     111        2.94      1\n",
       "      5 │                 74                     11     111        2.94      1 ⋯\n",
       "      6 │                 74                     11     111        2.94      1\n",
       "      7 │                 74                     11     111        2.94      1\n",
       "      8 │                 74                     11     111        2.94      1\n",
       "   ⋮    │         ⋮                     ⋮              ⋮         ⋮         ⋮   ⋱\n",
       " 394994 │               3021                     33     333        2.08      2 ⋯\n",
       " 394995 │               3021                     33     333        2.08      2\n",
       " 394996 │               3021                     33     333        2.08      2\n",
       " 394997 │               3021                     33     333        2.08      2\n",
       " 394998 │               3021                     33     333        2.08      2 ⋯\n",
       " 394999 │               3021                     33     333        2.08      2\n",
       " 395000 │               3021                     33     333        2.08      2\n",
       "\u001b[36m                                               2 columns and 394985 rows omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5cd8df06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(total_features = 40,\n",
       " total_samples = 394999,\n",
       " train_samples = 276499,\n",
       " test_samples = 118500,\n",
       " feature_names = [\"product_identifier\", \"department_identifier\", \"outlet\", \"sell_price\", \"Month\", \"DayOfWeek\", \"DayOfMonth\", \"Quarter\", \"WeekOfYear\", \"IsWeekend\"  …  \"outlet_frequency\", \"category_sales_mean\", \"state_sales_mean\", \"outlet_x_category\", \"state_x_category\", \"month_x_category\", \"products_per_outlet\", \"outlets_per_state\", \"state_encoded\", \"category_encoded\"],)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "using MLJ, DataFrames, CSV, Statistics, Dates, Random, CategoricalArrays\n",
    "using MLJ: @load, machine, fit!, predict\n",
    "using EvoTrees\n",
    "import DataFrames: transform\n",
    "\n",
    "# ========================================\n",
    "# 1. CARGA Y PREPARACIÓN INICIAL\n",
    "# ========================================\n",
    "\n",
    "df_train = DataFrame(CSV.File(\"dataO/train_data.csv\"))\n",
    "df_week = DataFrame(CSV.File(\"dataO/date_to_week_id_map.csv\"))\n",
    "df_prices = DataFrame(CSV.File(\"dataO/product_prices.csv\"))\n",
    "\n",
    "# Joins iniciales\n",
    "df = innerjoin(df_prices, df_week, on = :week_id)\n",
    "df_final = innerjoin(df_train, df, on = [:date, :product_identifier, :outlet])\n",
    "\n",
    "# ========================================\n",
    "# 2. FEATURES TEMPORALES AVANZADAS\n",
    "# ========================================\n",
    "\n",
    "# Features de tiempo básicas\n",
    "df_final.Month = month.(df_final.date)\n",
    "df_final.DayOfWeek = dayofweek.(df_final.date)\n",
    "df_final.DayOfMonth = day.(df_final.date)\n",
    "df_final.Quarter = quarterofyear.(df_final.date)\n",
    "df_final.WeekOfYear = week.(df_final.date)\n",
    "\n",
    "# Features estacionales\n",
    "df_final.IsWeekend = df_final.DayOfWeek .>= 6\n",
    "df_final.IsMonthStart = df_final.DayOfMonth .<= 7\n",
    "df_final.IsMonthEnd = df_final.DayOfMonth .>= 25\n",
    "df_final.IsHolidayMonth = (df_final.Month .== 12) .|| (df_final.Month .== 1)  # Diciembre/Enero\n",
    "\n",
    "# Features cíclicas (importantes para capturar patrones estacionales)\n",
    "df_final.Month_sin = sin.(2π * df_final.Month / 12)\n",
    "df_final.Month_cos = cos.(2π * df_final.Month / 12)\n",
    "df_final.DayOfWeek_sin = sin.(2π * df_final.DayOfWeek / 7)\n",
    "df_final.DayOfWeek_cos = cos.(2π * df_final.DayOfWeek / 7)\n",
    "\n",
    "# ========================================\n",
    "# 3. FEATURES DE PRECIOS\n",
    "# ========================================\n",
    "\n",
    "# Features de precios por grupos\n",
    "price_stats = combine(groupby(df_final, :product_identifier), \n",
    "    :sell_price => mean => :price_product_mean,\n",
    "    :sell_price => std => :price_product_std,\n",
    "    :sell_price => minimum => :price_product_min,\n",
    "    :sell_price => maximum => :price_product_max\n",
    ")\n",
    "\n",
    "outlet_price_stats = combine(groupby(df_final, :outlet),\n",
    "    :sell_price => mean => :price_outlet_mean,\n",
    "    :sell_price => std => :price_outlet_std\n",
    ")\n",
    "\n",
    "category_price_stats = combine(groupby(df_final, :category_of_product),\n",
    "    :sell_price => mean => :price_category_mean,\n",
    "    :sell_price => std => :price_category_std\n",
    ")\n",
    "\n",
    "# Unir estadísticas de precios\n",
    "df_final = leftjoin(df_final, price_stats, on = :product_identifier)\n",
    "df_final = leftjoin(df_final, outlet_price_stats, on = :outlet)\n",
    "df_final = leftjoin(df_final, category_price_stats, on = :category_of_product)\n",
    "\n",
    "# Features derivadas de precios\n",
    "df_final.price_vs_product_mean = df_final.sell_price ./ df_final.price_product_mean\n",
    "df_final.price_vs_outlet_mean = df_final.sell_price ./ df_final.price_outlet_mean\n",
    "df_final.price_vs_category_mean = df_final.sell_price ./ df_final.price_category_mean\n",
    "\n",
    "# Reemplazar NaN y valores infinitos con 1.0\n",
    "#for col in [:price_vs_product_mean, :price_vs_outlet_mean, :price_vs_category_mean]\n",
    "#    df_final[!, col] = replace(df_final[!, col], NaN => 1.0, Inf => 1.0, -Inf => 1.0)\n",
    "#end\n",
    "\n",
    "# Limpieza rápida de NaN/Inf:\n",
    "for col in [:price_vs_product_mean, :price_vs_outlet_mean, :price_vs_category_mean]\n",
    "    df_final[!, col] = [ (v isa Missing || isnan(v) || isinf(v)) ? 1.0 : v\n",
    "                         for v in df_final[!, col] ]\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 4. FEATURES DE VENTAS HISTÓRICAS (LAG FEATURES)\n",
    "# ========================================\n",
    "\n",
    "# Ordenar por producto, outlet y fecha\n",
    "sort!(df_final, [:product_identifier, :outlet, :date])\n",
    "\n",
    "# Lag features de ventas (ventas de días anteriores)\n",
    "df_final.sales_lag_1 = [missing; df_final.sales[1:end-1]]\n",
    "df_final.sales_lag_7 = [fill(missing, 7); df_final.sales[1:end-7]]\n",
    "\n",
    "# Promedios móviles de ventas\n",
    "function rolling_mean(x, window)\n",
    "    result = similar(x, Float64)\n",
    "    for i in 1:length(x)\n",
    "        start_idx = max(1, i - window + 1)\n",
    "        result[i] = mean(x[start_idx:i])\n",
    "    end\n",
    "    return result\n",
    "end\n",
    "\n",
    "df_final.sales_rolling_3 = rolling_mean(df_final.sales, 3)\n",
    "df_final.sales_rolling_7 = rolling_mean(df_final.sales, 7)\n",
    "df_final.sales_rolling_30 = rolling_mean(df_final.sales, 30)\n",
    "\n",
    "# NUEVAS FEATURES\n",
    "\n",
    "# ========================================\n",
    "# 5. FEATURES ADICIONALES\n",
    "# ========================================\n",
    "\n",
    "# 5.1 Price & sales lag de 7 días\n",
    "df_final.sell_price_lag_7 = [fill(missing, 7); df_final.sell_price[1:end-7]]\n",
    "df_final.sales_lag_7      = [fill(missing, 7); df_final.sales[1:end-7]]\n",
    "\n",
    "# 5.2 Cambios porcentuales a 7 días\n",
    "df_final.price_pct_change_7 = [\n",
    "    (ismissing(p) || p == 0) ? 0.0 : (df_final.sell_price[i] - p) / p \n",
    "    for (i, p) in enumerate(df_final.sell_price_lag_7)\n",
    "]\n",
    "df_final.sales_pct_change_7 = [\n",
    "    (ismissing(s) || s == 0) ? 0.0 : (df_final.sales[i] - s) / s \n",
    "    for (i, s) in enumerate(df_final.sales_lag_7)\n",
    "]\n",
    "\n",
    "# 5.3 Elasticidad precio — respuesta de ventas al cambio de precio\n",
    "df_final.price_elasticity = [\n",
    "    pct == 0 ? 0.0 : sale_pct / pct\n",
    "    for (pct, sale_pct) in zip(df_final.price_pct_change_7, df_final.sales_pct_change_7)\n",
    "]\n",
    "\n",
    "# 5.4 Agregados semanales por producto-outlet\n",
    "# 1) Creas el DataFrame “weekly”\n",
    "\n",
    "#weekly = combine(groupby(df_final, [:product_identifier, :outlet, :week_id]),\n",
    "#                 :sales => sum => :weekly_sales)\n",
    "#sort!(weekly, [:product_identifier, :outlet, :week_id])\n",
    "\n",
    "# 2) paso 1: creas lag1\n",
    "#weekly = transform(groupby(weekly, [:product_identifier, :outlet]),\n",
    "#    :weekly_sales => (x->[missing; x[1:end-1]]) => :weekly_sales_lag1\n",
    "#)\n",
    "\n",
    "# 3) paso 2: creas growth (ahora :weekly_sales_lag1 ya existe)\n",
    "#weekly = transform(groupby(weekly, [:product_identifier, :outlet]),\n",
    "#    [:weekly_sales, :weekly_sales_lag1] => ((s,l)->\n",
    "#      [ (ismissing(li)||li==0) ? 0.0 : (si - li)/li\n",
    "#        for (si, li) in zip(s,l) ]\n",
    "#    ) => :weekly_growth\n",
    "#)\n",
    "\n",
    "# Unir back a df_final\n",
    "#df_final = leftjoin(df_final, weekly,\n",
    "#    on=[:product_identifier, :outlet, :week_id])\n",
    "\n",
    "# 5.5 Agregados mensuales por producto-outlet\n",
    "monthly = combine(groupby(df_final, [:product_identifier, :outlet, :Month]),\n",
    "                  :sales => sum => :monthly_sales)\n",
    "sort!(monthly, [:product_identifier, :outlet, :Month])\n",
    "\n",
    "# lag mensual y crecimiento\n",
    "#monthly.monthly_sales_lag1 = similar(monthly.monthly_sales)\n",
    "#for g in groupby(monthly, [:product_identifier, :outlet])\n",
    "#    idxs = g.rows\n",
    "#    monthly.monthly_sales_lag1[idxs] = [missing; g.monthly_sales[1:end-1]]\n",
    "#end\n",
    "#monthly.monthly_growth = [\n",
    "#    (ismissing(l) || l == 0) ? 0.0 : (m - l) / l\n",
    "#    for (m, l) in zip(monthly.monthly_sales, monthly.monthly_sales_lag1)\n",
    "#]\n",
    "\n",
    "# Unir back a df_final\n",
    "df_final = leftjoin(df_final, monthly,\n",
    "    on=[:product_identifier, :outlet, :Month])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 5. FEATURES AGREGADAS POR ENTIDADES\n",
    "# ========================================\n",
    "\n",
    "# Estadísticas por producto\n",
    "product_stats = combine(groupby(df_final, :product_identifier),\n",
    "    :sales => mean => :product_sales_mean,\n",
    "    :sales => std => :product_sales_std,\n",
    "    :sales => sum => :product_total_sales,\n",
    "    nrow => :product_frequency\n",
    ")\n",
    "\n",
    "# Estadísticas por outlet\n",
    "outlet_stats = combine(groupby(df_final, :outlet),\n",
    "    :sales => mean => :outlet_sales_mean,\n",
    "    :sales => std => :outlet_sales_std,\n",
    "    :sales => sum => :outlet_total_sales,\n",
    "    nrow => :outlet_frequency\n",
    ")\n",
    "\n",
    "# Estadísticas por categoría\n",
    "category_stats = combine(groupby(df_final, :category_of_product),\n",
    "    :sales => mean => :category_sales_mean,\n",
    "    :sales => std => :category_sales_std,\n",
    "    :sales => sum => :category_total_sales\n",
    ")\n",
    "\n",
    "# Estadísticas por estado\n",
    "state_stats = combine(groupby(df_final, :state),\n",
    "    :sales => mean => :state_sales_mean,\n",
    "    :sales => std => :state_sales_std,\n",
    "    :sales => sum => :state_total_sales\n",
    ")\n",
    "\n",
    "# Unir todas las estadísticas\n",
    "df_final = leftjoin(df_final, product_stats, on = :product_identifier)\n",
    "df_final = leftjoin(df_final, outlet_stats, on = :outlet)\n",
    "df_final = leftjoin(df_final, category_stats, on = :category_of_product)\n",
    "df_final = leftjoin(df_final, state_stats, on = :state)\n",
    "\n",
    "# ========================================\n",
    "# 6. FEATURES DE INTERACCIONES\n",
    "# ========================================\n",
    "\n",
    "# Interacciones importantes\n",
    "df_final.outlet_x_category = df_final.outlet .* 1000 .+ hash.(df_final.category_of_product) .% 1000\n",
    "df_final.state_x_category = hash.(df_final.state) .% 100 .* 1000 .+ hash.(df_final.category_of_product) .% 1000\n",
    "df_final.month_x_category = df_final.Month .* 1000 .+ hash.(df_final.category_of_product) .% 1000\n",
    "\n",
    "# Features de densidad/competencia\n",
    "df_final.products_per_outlet = df_final.outlet_frequency ./ length(unique(df_final.product_identifier))\n",
    "df_final.outlets_per_state = [length(unique(df_final[df_final.state .== s, :outlet])) for s in df_final.state]\n",
    "\n",
    "# ========================================\n",
    "# 7. ENCODING DE VARIABLES CATEGÓRICAS\n",
    "# ========================================\n",
    "\n",
    "# Convertir a categóricas\n",
    "df_final.category_of_product = categorical(df_final.category_of_product)\n",
    "df_final.state = categorical(df_final.state)\n",
    "\n",
    "# Crear encodings\n",
    "df_final.state_encoded = levelcode.(df_final.state)\n",
    "df_final.category_encoded = levelcode.(df_final.category_of_product)\n",
    "\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 8. SELECCIÓN DE FEATURES FINALES\n",
    "# ========================================\n",
    "\n",
    "# Eliminar filas con missing values en lag features (para simplificar)\n",
    "df_final = df_final[.!ismissing.(df_final.sales_lag_1), :]\n",
    "\n",
    "# Seleccionar features finales\n",
    "feature_columns = [\n",
    "    # Features básicas\n",
    "    :product_identifier, :department_identifier, :outlet, :sell_price,\n",
    "    \n",
    "    # Features temporales\n",
    "    :Month, :DayOfWeek, :DayOfMonth, :Quarter, :WeekOfYear,\n",
    "    :IsWeekend, :IsMonthStart, :IsMonthEnd, :IsHolidayMonth,\n",
    "    :Month_sin, :Month_cos, :DayOfWeek_sin, :DayOfWeek_cos,\n",
    "    \n",
    "    # Features de precios\n",
    "    :price_product_mean, :price_outlet_mean, :price_category_mean,\n",
    "    :price_vs_product_mean, :price_vs_outlet_mean, :price_vs_category_mean,\n",
    "    \n",
    "    # Features de ventas históricas\n",
    "    :sales_lag_1, :sales_rolling_3, :sales_rolling_7, :sales_rolling_30,\n",
    "    \n",
    "    # Features agregadas\n",
    "    :product_sales_mean, :product_frequency, :outlet_sales_mean, :outlet_frequency,\n",
    "    :category_sales_mean, :state_sales_mean,\n",
    "    \n",
    "    # Features de interacciones\n",
    "    :outlet_x_category, :state_x_category, :month_x_category,\n",
    "    :products_per_outlet, :outlets_per_state,\n",
    "    \n",
    "    # Encodings categóricos\n",
    "    :state_encoded, :category_encoded\n",
    "\n",
    "    #NUEVAS\n",
    "    #:sales_lag_1, \n",
    "    #:sales_lag_7,\n",
    "    #:sell_price_lag_7,\n",
    "    #:price_pct_change_7, :sales_pct_change_7,\n",
    "    #:price_elasticity,\n",
    "    #:weekly_sales, :weekly_sales_lag1, :weekly_growth,\n",
    "    #:monthly_sales, #:monthly_sales_lag1, \n",
    "    #:monthly_growth,\n",
    "\n",
    "]\n",
    "\n",
    "X_engineered = df_final[!, feature_columns]\n",
    "y_engineered = df_final.sales\n",
    "\n",
    "# Verificar que no hay missing values\n",
    "for col in names(X_engineered)\n",
    "    if any(ismissing.(X_engineered[!, col]))\n",
    "        println(\"Warning: Missing values en $col\")\n",
    "    end\n",
    "end\n",
    "\n",
    "# ========================================\n",
    "# 9. DIVISIÓN Y EVALUACIÓN\n",
    "# ========================================\n",
    "\n",
    "# División train/test\n",
    "Random.seed!(42)\n",
    "n = nrow(X_engineered)\n",
    "train_size = floor(Int, 0.7 * n)\n",
    "perm = randperm(n)\n",
    "\n",
    "X_train = X_engineered[perm[1:train_size], :]\n",
    "X_test = X_engineered[perm[train_size+1:end], :]\n",
    "y_train = y_engineered[perm[1:train_size]]\n",
    "y_test = y_engineered[perm[train_size+1:end]]\n",
    "\n",
    "# Información sobre las features\n",
    "feature_info = (\n",
    "    total_features = ncol(X_engineered),\n",
    "    total_samples = nrow(X_engineered),\n",
    "    train_samples = nrow(X_train),\n",
    "    test_samples = nrow(X_test),\n",
    "    feature_names = names(X_engineered)\n",
    ")\n",
    "\n",
    "feature_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c967830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any}()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "missing_summary = Dict()\n",
    "for col in names(X_train)\n",
    "    missing_count = sum(ismissing.(X_train[!, col]))\n",
    "    if missing_count > 0\n",
    "        missing_summary[col] = missing_count\n",
    "    end\n",
    "end\n",
    "\n",
    "missing_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101b0206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(X_train_types = DataType[Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64  …  Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64],\n",
       " y_train_type = Float64,\n",
       " dimensions = (276499, 40),)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convertir todos los datos a tipos numéricos estándar (homogeniza los datos)\n",
    "function fix_data_types(X, y)\n",
    "    X_fixed = DataFrame()\n",
    "    \n",
    "    for col in names(X)\n",
    "        if eltype(X[!, col]) <: Union{Missing, Number}\n",
    "            # Convertir a Float64, reemplazando missing con 0.0\n",
    "            X_fixed[!, col] = convert(Vector{Float64}, coalesce.(X[!, col], 0.0))\n",
    "        else\n",
    "            # Para otros tipos, convertir directamente\n",
    "            X_fixed[!, col] = convert(Vector{Float64}, X[!, col])\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    y_fixed = convert(Vector{Float64}, y)\n",
    "    \n",
    "    return X_fixed, y_fixed\n",
    "end\n",
    "\n",
    "# Aplicar la corrección\n",
    "X_train_fixed, y_train_fixed = fix_data_types(X_train, y_train)\n",
    "X_test_fixed, y_test_fixed = fix_data_types(X_test, y_test)\n",
    "\n",
    "# Verificar tipos\n",
    "(\n",
    "    X_train_types = eltype.(eachcol(X_train_fixed)),\n",
    "    y_train_type = eltype(y_train_fixed),\n",
    "    dimensions = (nrow(X_train_fixed), ncol(X_train_fixed))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0272db10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pkg.add(\"MLJLightGBMInterface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8b09cbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1837\n",
      "[LightGBM] [Info] Number of data points in the train set: 276499, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227494\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1837\n",
      "[LightGBM] [Info] Number of data points in the train set: 276499, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227494\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1837\n",
      "[LightGBM] [Info] Number of data points in the train set: 276499, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227494\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>9×5 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Model</th><th style = \"text-align: left;\">MAE</th><th style = \"text-align: left;\">RMSE</th><th style = \"text-align: left;\">R2</th><th style = \"text-align: left;\">Features</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">LGBM_Default_FE</td><td style = \"text-align: right;\">0.594825</td><td style = \"text-align: right;\">1.62456</td><td style = \"text-align: right;\">0.775698</td><td style = \"text-align: right;\">40</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">LGBM_100_FE</td><td style = \"text-align: right;\">0.594825</td><td style = \"text-align: right;\">1.62456</td><td style = \"text-align: right;\">0.775698</td><td style = \"text-align: right;\">40</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">LGBM_200_FE</td><td style = \"text-align: right;\">0.591386</td><td style = \"text-align: right;\">1.63568</td><td style = \"text-align: right;\">0.772614</td><td style = \"text-align: right;\">40</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">LinearRegression_FE</td><td style = \"text-align: right;\">0.655862</td><td style = \"text-align: right;\">1.65888</td><td style = \"text-align: right;\">0.766118</td><td style = \"text-align: right;\">40</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">Ridge_1.0_FE</td><td style = \"text-align: right;\">0.713618</td><td style = \"text-align: right;\">1.81293</td><td style = \"text-align: right;\">0.720664</td><td style = \"text-align: right;\">40</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">EvoTree_100_FE</td><td style = \"text-align: right;\">0.619101</td><td style = \"text-align: right;\">1.90706</td><td style = \"text-align: right;\">0.690904</td><td style = \"text-align: right;\">40</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">EvoTree_200_FE</td><td style = \"text-align: right;\">0.624935</td><td style = \"text-align: right;\">1.95064</td><td style = \"text-align: right;\">0.676617</td><td style = \"text-align: right;\">40</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">KNN_25_FE</td><td style = \"text-align: right;\">0.993251</td><td style = \"text-align: right;\">2.35886</td><td style = \"text-align: right;\">0.527102</td><td style = \"text-align: right;\">40</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">KNN_35_FE</td><td style = \"text-align: right;\">1.02405</td><td style = \"text-align: right;\">2.45056</td><td style = \"text-align: right;\">0.489617</td><td style = \"text-align: right;\">40</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& Model & MAE & RMSE & R2 & Features\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & LGBM\\_Default\\_FE & 0.594825 & 1.62456 & 0.775698 & 40 \\\\\n",
       "\t2 & LGBM\\_100\\_FE & 0.594825 & 1.62456 & 0.775698 & 40 \\\\\n",
       "\t3 & LGBM\\_200\\_FE & 0.591386 & 1.63568 & 0.772614 & 40 \\\\\n",
       "\t4 & LinearRegression\\_FE & 0.655862 & 1.65888 & 0.766118 & 40 \\\\\n",
       "\t5 & Ridge\\_1.0\\_FE & 0.713618 & 1.81293 & 0.720664 & 40 \\\\\n",
       "\t6 & EvoTree\\_100\\_FE & 0.619101 & 1.90706 & 0.690904 & 40 \\\\\n",
       "\t7 & EvoTree\\_200\\_FE & 0.624935 & 1.95064 & 0.676617 & 40 \\\\\n",
       "\t8 & KNN\\_25\\_FE & 0.993251 & 2.35886 & 0.527102 & 40 \\\\\n",
       "\t9 & KNN\\_35\\_FE & 1.02405 & 2.45056 & 0.489617 & 40 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m9×5 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Model               \u001b[0m\u001b[1m MAE      \u001b[0m\u001b[1m RMSE    \u001b[0m\u001b[1m R2       \u001b[0m\u001b[1m Features \u001b[0m\n",
       "     │\u001b[90m String              \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Int64    \u001b[0m\n",
       "─────┼────────────────────────────────────────────────────────────\n",
       "   1 │ LGBM_Default_FE      0.594825  1.62456  0.775698        40\n",
       "   2 │ LGBM_100_FE          0.594825  1.62456  0.775698        40\n",
       "   3 │ LGBM_200_FE          0.591386  1.63568  0.772614        40\n",
       "   4 │ LinearRegression_FE  0.655862  1.65888  0.766118        40\n",
       "   5 │ Ridge_1.0_FE         0.713618  1.81293  0.720664        40\n",
       "   6 │ EvoTree_100_FE       0.619101  1.90706  0.690904        40\n",
       "   7 │ EvoTree_200_FE       0.624935  1.95064  0.676617        40\n",
       "   8 │ KNN_25_FE            0.993251  2.35886  0.527102        40\n",
       "   9 │ KNN_35_FE            1.02405   2.45056  0.489617        40"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modelos completos con feature engineering\n",
    "\n",
    "using MLJ\n",
    "#using  MLJLightGBMInterface\n",
    "\n",
    "\n",
    "fe_models = Dict(\n",
    "    \"LinearRegression_FE\" => LinearRegressor(),\n",
    "    \"Ridge_1.0_FE\" => RidgeRegressor(lambda=1.0),\n",
    "    \"KNN_25_FE\" => KNNRegressor(K=25),\n",
    "    \"KNN_35_FE\" => KNNRegressor(K=35),\n",
    "    \"EvoTree_100_FE\" => EvoTreeRegressor(nrounds=100),\n",
    "    \"EvoTree_200_FE\" => EvoTreeRegressor(nrounds=200),\n",
    "    # LightGBM con feature engineering\n",
    "    \"LGBM_Default_FE\"     => LGBMRegressor(),\n",
    "    \"LGBM_100_FE\"         => LGBMRegressor(\n",
    "                               num_iterations=100,\n",
    "                               learning_rate=0.1,\n",
    "                               num_leaves=31\n",
    "                            ),\n",
    "    \"LGBM_200_FE\"         => LGBMRegressor(\n",
    "                               num_iterations=200,\n",
    "                               learning_rate=0.05,\n",
    "                               num_leaves=50\n",
    "                            )\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluar todos\n",
    "results_final_fe = DataFrame(\n",
    "    Model = String[],\n",
    "    MAE = Float64[],\n",
    "    RMSE = Float64[],\n",
    "    R2 = Float64[],\n",
    "    Features = Int64[]\n",
    ")\n",
    "\n",
    "for (name, model) in fe_models\n",
    "    mach = machine(model, X_train_fixed, y_train_fixed)\n",
    "    fit!(mach, verbosity=0)\n",
    "    ŷ = predict(mach, X_test_fixed)\n",
    "    \n",
    "    mae_val = mean(abs.(ŷ .- y_test_fixed))\n",
    "    rmse_val = sqrt(mean((ŷ .- y_test_fixed).^2))\n",
    "    r2_val = 1 - sum((y_test_fixed .- ŷ).^2) / sum((y_test_fixed .- mean(y_test_fixed)).^2)\n",
    "    \n",
    "    push!(results_final_fe, (name, mae_val, rmse_val, r2_val, ncol(X_train_fixed)))\n",
    "end\n",
    "\n",
    "sort(results_final_fe, :RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166c0880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\natal\\.julia\\environments\\v1.10\\Project.toml`\n",
      "  \u001b[90m[03970b2e] \u001b[39m\u001b[92m+ MLJTuning v0.8.8\u001b[39m\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\natal\\.julia\\environments\\v1.10\\Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "#Pkg.add(\"MLJTuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6e8d8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\natal\\.julia\\environments\\v1.10\\Project.toml`\n",
      "  \u001b[90m[4c6ed407] \u001b[39m\u001b[92m+ BayesianOptimization v0.2.5\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\natal\\.julia\\environments\\v1.10\\Manifest.toml`\n",
      "  \u001b[90m[4c6ed407] \u001b[39m\u001b[92m+ BayesianOptimization v0.2.5\u001b[39m\n",
      "  \u001b[90m[6e4b80f9] \u001b[39m\u001b[92m+ BenchmarkTools v1.6.0\u001b[39m\n",
      "  \u001b[90m[523fee87] \u001b[39m\u001b[92m+ CodecBzip2 v0.8.5\u001b[39m\n",
      "  \u001b[90m[fdbdab4c] \u001b[39m\u001b[92m+ ElasticArrays v1.2.12\u001b[39m\n",
      "  \u001b[90m[2904ab23] \u001b[39m\u001b[92m+ ElasticPDMats v0.2.3\u001b[39m\n",
      "  \u001b[90m[e2ba6199] \u001b[39m\u001b[92m+ ExprTools v0.1.10\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[442a2c76] \u001b[39m\u001b[92m+ FastGaussQuadrature v0.4.9\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[f6369f11] \u001b[39m\u001b[95m↓ ForwardDiff v1.0.1 ⇒ v0.10.38\u001b[39m\n",
      "  \u001b[90m[891a1506] \u001b[39m\u001b[92m+ GaussianProcesses v0.12.5\u001b[39m\n",
      "  \u001b[90m[076d061b] \u001b[39m\u001b[91m- HashArrayMappedTries v0.2.0\u001b[39m\n",
      "  \u001b[90m[34004b35] \u001b[39m\u001b[91m- HypergeometricFunctions v0.3.28\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[92d709cd] \u001b[39m\u001b[95m↓ IrrationalConstants v0.2.4 ⇒ v0.1.1\u001b[39m\n",
      "  \u001b[90m[0f8b85d8] \u001b[39m\u001b[92m+ JSON3 v1.14.3\u001b[39m\n",
      "  \u001b[90m[b8f27783] \u001b[39m\u001b[92m+ MathOptInterface v1.42.0\u001b[39m\n",
      "  \u001b[90m[fdba3010] \u001b[39m\u001b[92m+ MathProgBase v0.7.8\u001b[39m\n",
      "  \u001b[90m[d8a4904e] \u001b[39m\u001b[92m+ MutableArithmetics v1.6.4\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[76087f3c] \u001b[39m\u001b[92m+ NLopt v0.6.5\u001b[39m\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[872c559c] \u001b[39m\u001b[95m↓ NNlib v0.9.30 ⇒ v0.9.28\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[79098fc4] \u001b[39m\u001b[95m↓ Rmath v0.8.0 ⇒ v0.7.1\u001b[39m\n",
      "  \u001b[90m[7e506255] \u001b[39m\u001b[91m- ScopedValues v1.3.0\u001b[39m\n",
      "  \u001b[90m[ed01d8cd] \u001b[39m\u001b[92m+ Sobol v1.5.0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[276daf66] \u001b[39m\u001b[95m↓ SpecialFunctions v2.5.1 ⇒ v1.8.8\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[4c63d2b9] \u001b[39m\u001b[95m↓ StatsFuns v1.5.0 ⇒ v0.9.18\u001b[39m\n",
      "  \u001b[90m[856f2bd8] \u001b[39m\u001b[92m+ StructTypes v1.11.0\u001b[39m\n",
      "  \u001b[90m[a759f4b9] \u001b[39m\u001b[92m+ TimerOutputs v0.5.29\u001b[39m\n",
      "  \u001b[90m[6e34b625] \u001b[39m\u001b[92m+ Bzip2_jll v1.0.9+0\u001b[39m\n",
      "  \u001b[90m[079eb43e] \u001b[39m\u001b[92m+ NLopt_jll v2.10.0+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[f50d1b31] \u001b[39m\u001b[95m↓ Rmath_jll v0.5.1+0 ⇒ v0.4.3+0\u001b[39m\n",
      "  \u001b[90m[9abbd945] \u001b[39m\u001b[92m+ Profile\u001b[39m\n",
      "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m Packages marked with \u001b[32m⌃\u001b[39m and \u001b[33m⌅\u001b[39m have new versions available. Those with \u001b[32m⌃\u001b[39m may be upgradable, but those with \u001b[33m⌅\u001b[39m are restricted by compatibility constraints from upgrading. To see why use `status --outdated -m`\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m packages...\n",
      "   5112.6 ms\u001b[33m  ✓ \u001b[39m\u001b[90mSpecialFunctions\u001b[39m\n",
      "   1667.9 ms\u001b[33m  ✓ \u001b[39m\u001b[90mNNlib → NNlibSpecialFunctionsExt\u001b[39m\n",
      "   2897.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mFastGaussQuadrature\u001b[39m\n",
      "   3968.2 ms\u001b[33m  ✓ \u001b[39m\u001b[90mStatsFuns\u001b[39m\n",
      "   4928.4 ms\u001b[33m  ✓ \u001b[39m\u001b[90mForwardDiff\u001b[39m\n",
      "┌ Warning: attempting to remove probably stale pidfile\n",
      "│   path = C:\\Users\\natal\\.julia\\compiled\\v1.10\\MathOptInterface\\tyub8_urZjT.ji.pidfile\n",
      "└ @ FileWatching.Pidfile C:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\pidfile.jl:244\n",
      "   1200.9 ms\u001b[33m  ✓ \u001b[39m\u001b[90mForwardDiff → ForwardDiffStaticArraysExt\u001b[39m\n",
      "   2008.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mInterpolations → InterpolationsForwardDiffExt\u001b[39m\n",
      "   2680.2 ms\u001b[33m  ✓ \u001b[39m\u001b[90mNNlib → NNlibForwardDiffExt\u001b[39m\n",
      "  24909.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mGaussianProcesses\u001b[39m\n",
      "  41357.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMathOptInterface\u001b[39m\n",
      "┌ Warning: attempting to remove probably stale pidfile\n",
      "│   path = C:\\Users\\natal\\.julia\\compiled\\v1.10\\NLopt\\faRdv_urZjT.ji.pidfile\n",
      "└ @ FileWatching.Pidfile C:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\pidfile.jl:244\n",
      "   2500.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mOptim → OptimMOIExt\u001b[39m\n",
      "   3420.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mNLopt\u001b[39m\n",
      "┌ Warning: attempting to remove probably stale pidfile\n",
      "│   path = C:\\Users\\natal\\.julia\\compiled\\v1.10\\BayesianOptimization\\RWvRj_urZjT.ji.pidfile\n",
      "└ @ FileWatching.Pidfile C:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\pidfile.jl:244\n",
      "   6242.0 ms\u001b[32m  ✓ \u001b[39mBayesianOptimization\n",
      "  13 dependencies successfully precompiled in 65 seconds. 294 already precompiled.\n",
      "  \u001b[33m6\u001b[39m dependencies precompiled but different versions are currently loaded. Restart julia to access the new versions\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"BayesianOptimization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014426cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\natal\\.julia\\environments\\v1.10\\Project.toml`\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[31c24e10] \u001b[39m\u001b[95m↓ Distributions v0.25.120 ⇒ v0.25.45\u001b[39m\n",
      "  \u001b[90m[eb66a70c] \u001b[39m\u001b[92m+ TreeParzen v0.3.4\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\natal\\.julia\\environments\\v1.10\\Manifest.toml`\n",
      "  \u001b[90m[66dad0bd] \u001b[39m\u001b[91m- AliasTables v1.1.3\u001b[39m\n",
      "  \u001b[90m[9e28174c] \u001b[39m\u001b[92m+ BinDeps v1.0.2\u001b[39m\n",
      "  \u001b[90m[b99e7846] \u001b[39m\u001b[92m+ BinaryProvider v0.5.10\u001b[39m\n",
      "  \u001b[90m[a2441757] \u001b[39m\u001b[92m+ Coverage v1.6.1\u001b[39m\n",
      "  \u001b[90m[c36e975a] \u001b[39m\u001b[92m+ CoverageTools v1.3.2\u001b[39m\n",
      "  \u001b[90m[b429d917] \u001b[39m\u001b[92m+ DensityInterface v0.4.0\u001b[39m\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[b552c78f] \u001b[39m\u001b[95m↓ DiffRules v1.15.1 ⇒ v1.7.0\u001b[39m\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[31c24e10] \u001b[39m\u001b[95m↓ Distributions v0.25.120 ⇒ v0.25.45\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[1a297f60] \u001b[39m\u001b[95m↓ FillArrays v1.13.0 ⇒ v0.12.8\u001b[39m\n",
      "  \u001b[90m[92d709cd] \u001b[39m\u001b[93m↑ IrrationalConstants v0.1.1 ⇒ v0.2.4\u001b[39m\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[d3d80556] \u001b[39m\u001b[95m↓ LineSearches v7.4.0 ⇒ v7.1.1\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[77ba4419] \u001b[39m\u001b[95m↓ NaNMath v1.1.3 ⇒ v0.3.7\u001b[39m\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[429524aa] \u001b[39m\u001b[95m↓ Optim v1.13.2 ⇒ v1.12.0\u001b[39m\n",
      "  \u001b[90m[43287f4e] \u001b[39m\u001b[91m- PtrArrays v1.3.0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[276daf66] \u001b[39m\u001b[95m↓ SpecialFunctions v1.8.8 ⇒ v0.8.0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[4c63d2b9] \u001b[39m\u001b[95m↓ StatsFuns v0.9.18 ⇒ v0.9.7\u001b[39m\n",
      "  \u001b[90m[eb66a70c] \u001b[39m\u001b[92m+ TreeParzen v0.3.4\u001b[39m\n",
      "  \u001b[90m[30578b45] \u001b[39m\u001b[92m+ URIParser v0.4.1\u001b[39m\n",
      "  \u001b[90m[efe28fd5] \u001b[39m\u001b[91m- OpenSpecFun_jll v0.5.6+0\u001b[39m\n",
      "  \u001b[90m[05823500] \u001b[39m\u001b[91m- OpenLibm_jll v0.8.5+0\u001b[39m\n",
      "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m Packages marked with \u001b[32m⌃\u001b[39m and \u001b[33m⌅\u001b[39m have new versions available. Those with \u001b[32m⌃\u001b[39m may be upgradable, but those with \u001b[33m⌅\u001b[39m are restricted by compatibility constraints from upgrading. To see why use `status --outdated -m`\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m packages...\n",
      "         \u001b[91m  ✗ \u001b[39m\u001b[90mBinaryProvider\u001b[39m\n",
      "         \u001b[91m  ✗ \u001b[39m\u001b[90mSpecialFunctions\u001b[39m\n",
      "         \u001b[91m  ✗ \u001b[39m\u001b[90mStatsFuns\u001b[39m\n",
      "         \u001b[91m  ✗ \u001b[39m\u001b[90mNNlib → NNlibSpecialFunctionsExt\u001b[39m\n",
      "         \u001b[91m  ✗ \u001b[39m\u001b[90mForwardDiff\u001b[39m\n",
      "         \u001b[91m  ✗ \u001b[39mDistributions\n",
      "         \u001b[91m  ✗ \u001b[39m\u001b[90mForwardDiff → ForwardDiffStaticArraysExt\u001b[39m\n",
      "         \u001b[91m  ✗ \u001b[39m\u001b[90mLineSearches\u001b[39m\n",
      "         \u001b[91m  ✗ \u001b[39mTreeParzen\n",
      "         \u001b[91m  ✗ \u001b[39m\u001b[90mInterpolations → InterpolationsForwardDiffExt\u001b[39m\n",
      "         \u001b[91m  ✗ \u001b[39m\u001b[90mNNlib → NNlibForwardDiffExt\u001b[39m\n",
      "         \u001b[91m  ✗ \u001b[39m\u001b[90mOptim\u001b[39m\n",
      "         \u001b[91m  ✗ \u001b[39m\u001b[90mGaussianProcesses\u001b[39m\n",
      "         \u001b[91m  ✗ \u001b[39m\u001b[90mOptim → OptimMOIExt\u001b[39m\n",
      "         \u001b[91m  ✗ \u001b[39mBayesianOptimization\n",
      "  0 dependencies successfully precompiled in 68 seconds. 290 already precompiled.\n",
      "\n",
      "The following 3 direct dependencies failed to precompile:\n",
      "\n",
      "TreeParzen \n",
      "\n",
      "Failed to precompile TreeParzen [eb66a70c-a255-11e9-03ea-7ba6b2f22006] to \"C:\\\\Users\\\\natal\\\\.julia\\\\compiled\\\\v1.10\\\\TreeParzen\\\\jl_9A33.tmp\".\n",
      "\u001b[91m\u001b[1mERROR: \u001b[22m\u001b[39mLoadError: SpecialFunctions is not installed properly, run `Pkg.build(\"SpecialFunctions\")`,restart Julia and try again\n",
      "Stacktrace:\n",
      " [1] \u001b[0m\u001b[1merror\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90ms\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4merror.jl:35\u001b[24m\u001b[39m\n",
      " [2] top-level scope\n",
      "\u001b[90m   @\u001b[39m \u001b[90mC:\\Users\\natal\\.julia\\packages\\SpecialFunctions\\ne2iw\\src\\\u001b[39m\u001b[90m\u001b[4mSpecialFunctions.jl:6\u001b[24m\u001b[39m\n",
      " [3] \u001b[0m\u001b[1minclude\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:495\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [4] \u001b[0m\u001b[1minclude_package_for_output\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90minput\u001b[39m::\u001b[0mString, \u001b[90mdepot_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mdl_load_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mload_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mconcrete_deps\u001b[39m::\u001b[0mVector\u001b[90m{Pair{Base.PkgId, UInt128}}\u001b[39m, \u001b[90msource\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2292\u001b[24m\u001b[39m\n",
      " [5] top-level scope\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mstdin:4\u001b[24m\u001b[39m\n",
      "in expression starting at C:\\Users\\natal\\.julia\\packages\\SpecialFunctions\\ne2iw\\src\\SpecialFunctions.jl:1\n",
      "in expression starting at stdin:4\n",
      "\u001b[91m\u001b[1mERROR: \u001b[22m\u001b[39mLoadError: Failed to precompile SpecialFunctions [276daf66-3868-5448-9aa4-cd146d93841b] to \"C:\\\\Users\\\\natal\\\\.julia\\\\compiled\\\\v1.10\\\\SpecialFunctions\\\\jl_A89C.tmp\".\n",
      "Stacktrace:\n",
      "  [1] \u001b[0m\u001b[1merror\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90ms\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4merror.jl:35\u001b[24m\u001b[39m\n",
      "  [2] \u001b[0m\u001b[1mcompilecache\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90mpath\u001b[39m::\u001b[0mString, \u001b[90minternal_stderr\u001b[39m::\u001b[0mIO, \u001b[90minternal_stdout\u001b[39m::\u001b[0mIO, \u001b[90mkeep_loaded_modules\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2539\u001b[24m\u001b[39m\n",
      "  [3] \u001b[0m\u001b[1mcompilecache\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2411\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [4] \u001b[0m\u001b[1m(::Base.var\"#971#972\"{Base.PkgId})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2044\u001b[24m\u001b[39m\n",
      "  [5] \u001b[0m\u001b[1mmkpidlock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mBase.var\"#971#972\"\u001b[90m{Base.PkgId}\u001b[39m, \u001b[90mat\u001b[39m::\u001b[0mString, \u001b[90mpid\u001b[39m::\u001b[0mInt32; \u001b[90mkwopts\u001b[39m::\u001b[0m@Kwargs\u001b[90m{stale_age::Int64, wait::Bool}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mFileWatching.Pidfile\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:93\u001b[24m\u001b[39m\n",
      "  [6] \u001b[0m\u001b[1m#mkpidlock#6\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:88\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [7] \u001b[0m\u001b[1mtrymkpidlock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m::\u001b[0mFunction, ::\u001b[0mVararg\u001b[90m{Any}\u001b[39m; \u001b[90mkwargs\u001b[39m::\u001b[0m@Kwargs\u001b[90m{stale_age::Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mFileWatching.Pidfile\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:111\u001b[24m\u001b[39m\n",
      "  [8] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:894\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [9] \u001b[0m\u001b[1minvokelatest\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:889\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [10] \u001b[0m\u001b[1mmaybe_cachefile_lock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mBase.var\"#971#972\"\u001b[90m{Base.PkgId}\u001b[39m, \u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90msrcpath\u001b[39m::\u001b[0mString; \u001b[90mstale_age\u001b[39m::\u001b[0mInt64\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:3054\u001b[24m\u001b[39m\n",
      " [11] \u001b[0m\u001b[1mmaybe_cachefile_lock\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:3051\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [12] \u001b[0m\u001b[1m_require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2040\u001b[24m\u001b[39m\n",
      " [13] \u001b[0m\u001b[1m__require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1882\u001b[24m\u001b[39m\n",
      " [14] \u001b[0m\u001b[1m#invoke_in_world#3\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:926\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [15] \u001b[0m\u001b[1minvoke_in_world\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:923\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [16] \u001b[0m\u001b[1m_require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1873\u001b[24m\u001b[39m\n",
      " [17] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1860\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [18] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlock.jl:267\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [19] \u001b[0m\u001b[1m__require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1823\u001b[24m\u001b[39m\n",
      " [20] \u001b[0m\u001b[1m#invoke_in_world#3\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:926\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [21] \u001b[0m\u001b[1minvoke_in_world\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:923\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [22] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1816\u001b[24m\u001b[39m\n",
      " [23] \u001b[0m\u001b[1minclude\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:495\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [24] \u001b[0m\u001b[1minclude_package_for_output\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90minput\u001b[39m::\u001b[0mString, \u001b[90mdepot_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mdl_load_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mload_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mconcrete_deps\u001b[39m::\u001b[0mVector\u001b[90m{Pair{Base.PkgId, UInt128}}\u001b[39m, \u001b[90msource\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2292\u001b[24m\u001b[39m\n",
      " [25] top-level scope\n",
      "\u001b[90m    @\u001b[39m \u001b[90m\u001b[4mstdin:4\u001b[24m\u001b[39m\n",
      "in expression starting at C:\\Users\\natal\\.julia\\packages\\StatsFuns\\P7Mci\\src\\StatsFuns.jl:3\n",
      "in expression starting at stdin:4\n",
      "\u001b[91m\u001b[1mERROR: \u001b[22m\u001b[39mLoadError: Failed to precompile StatsFuns [4c63d2b9-4356-54db-8cca-17b64c39e42c] to \"C:\\\\Users\\\\natal\\\\.julia\\\\compiled\\\\v1.10\\\\StatsFuns\\\\jl_A149.tmp\".\n",
      "Stacktrace:\n",
      "  [1] \u001b[0m\u001b[1merror\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90ms\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4merror.jl:35\u001b[24m\u001b[39m\n",
      "  [2] \u001b[0m\u001b[1mcompilecache\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90mpath\u001b[39m::\u001b[0mString, \u001b[90minternal_stderr\u001b[39m::\u001b[0mIO, \u001b[90minternal_stdout\u001b[39m::\u001b[0mIO, \u001b[90mkeep_loaded_modules\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2539\u001b[24m\u001b[39m\n",
      "  [3] \u001b[0m\u001b[1mcompilecache\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2411\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [4] \u001b[0m\u001b[1m(::Base.var\"#971#972\"{Base.PkgId})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2044\u001b[24m\u001b[39m\n",
      "  [5] \u001b[0m\u001b[1mmkpidlock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mBase.var\"#971#972\"\u001b[90m{Base.PkgId}\u001b[39m, \u001b[90mat\u001b[39m::\u001b[0mString, \u001b[90mpid\u001b[39m::\u001b[0mInt32; \u001b[90mkwopts\u001b[39m::\u001b[0m@Kwargs\u001b[90m{stale_age::Int64, wait::Bool}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mFileWatching.Pidfile\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:93\u001b[24m\u001b[39m\n",
      "  [6] \u001b[0m\u001b[1m#mkpidlock#6\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:88\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [7] \u001b[0m\u001b[1mtrymkpidlock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m::\u001b[0mFunction, ::\u001b[0mVararg\u001b[90m{Any}\u001b[39m; \u001b[90mkwargs\u001b[39m::\u001b[0m@Kwargs\u001b[90m{stale_age::Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mFileWatching.Pidfile\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:111\u001b[24m\u001b[39m\n",
      "  [8] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:894\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [9] \u001b[0m\u001b[1minvokelatest\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:889\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [10] \u001b[0m\u001b[1mmaybe_cachefile_lock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mBase.var\"#971#972\"\u001b[90m{Base.PkgId}\u001b[39m, \u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90msrcpath\u001b[39m::\u001b[0mString; \u001b[90mstale_age\u001b[39m::\u001b[0mInt64\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:3054\u001b[24m\u001b[39m\n",
      " [11] \u001b[0m\u001b[1mmaybe_cachefile_lock\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:3051\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [12] \u001b[0m\u001b[1m_require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2040\u001b[24m\u001b[39m\n",
      " [13] \u001b[0m\u001b[1m__require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1882\u001b[24m\u001b[39m\n",
      " [14] \u001b[0m\u001b[1m#invoke_in_world#3\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:926\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [15] \u001b[0m\u001b[1minvoke_in_world\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:923\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [16] \u001b[0m\u001b[1m_require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1873\u001b[24m\u001b[39m\n",
      " [17] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1860\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [18] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlock.jl:267\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [19] \u001b[0m\u001b[1m__require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1823\u001b[24m\u001b[39m\n",
      " [20] \u001b[0m\u001b[1m#invoke_in_world#3\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:926\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [21] \u001b[0m\u001b[1minvoke_in_world\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:923\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [22] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1816\u001b[24m\u001b[39m\n",
      " [23] \u001b[0m\u001b[1minclude\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:495\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [24] \u001b[0m\u001b[1minclude_package_for_output\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90minput\u001b[39m::\u001b[0mString, \u001b[90mdepot_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mdl_load_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mload_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mconcrete_deps\u001b[39m::\u001b[0mVector\u001b[90m{Pair{Base.PkgId, UInt128}}\u001b[39m, \u001b[90msource\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2292\u001b[24m\u001b[39m\n",
      " [25] top-level scope\n",
      "\u001b[90m    @\u001b[39m \u001b[90m\u001b[4mstdin:4\u001b[24m\u001b[39m\n",
      "in expression starting at C:\\Users\\natal\\.julia\\packages\\Distributions\\9Albf\\src\\Distributions.jl:1\n",
      "in expression starting at stdin:4\n",
      "\u001b[91m\u001b[1mERROR: \u001b[22m\u001b[39mLoadError: Failed to precompile Distributions [31c24e10-a181-5473-b8eb-7969acd0382f] to \"C:\\\\Users\\\\natal\\\\.julia\\\\compiled\\\\v1.10\\\\Distributions\\\\jl_9E1D.tmp\".\n",
      "Stacktrace:\n",
      "  [1] \u001b[0m\u001b[1merror\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90ms\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4merror.jl:35\u001b[24m\u001b[39m\n",
      "  [2] \u001b[0m\u001b[1mcompilecache\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90mpath\u001b[39m::\u001b[0mString, \u001b[90minternal_stderr\u001b[39m::\u001b[0mIO, \u001b[90minternal_stdout\u001b[39m::\u001b[0mIO, \u001b[90mkeep_loaded_modules\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2539\u001b[24m\u001b[39m\n",
      "  [3] \u001b[0m\u001b[1mcompilecache\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2411\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [4] \u001b[0m\u001b[1m(::Base.var\"#971#972\"{Base.PkgId})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2044\u001b[24m\u001b[39m\n",
      "  [5] \u001b[0m\u001b[1mmkpidlock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mBase.var\"#971#972\"\u001b[90m{Base.PkgId}\u001b[39m, \u001b[90mat\u001b[39m::\u001b[0mString, \u001b[90mpid\u001b[39m::\u001b[0mInt32; \u001b[90mkwopts\u001b[39m::\u001b[0m@Kwargs\u001b[90m{stale_age::Int64, wait::Bool}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mFileWatching.Pidfile\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:93\u001b[24m\u001b[39m\n",
      "  [6] \u001b[0m\u001b[1m#mkpidlock#6\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:88\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [7] \u001b[0m\u001b[1mtrymkpidlock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m::\u001b[0mFunction, ::\u001b[0mVararg\u001b[90m{Any}\u001b[39m; \u001b[90mkwargs\u001b[39m::\u001b[0m@Kwargs\u001b[90m{stale_age::Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mFileWatching.Pidfile\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:111\u001b[24m\u001b[39m\n",
      "  [8] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:894\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [9] \u001b[0m\u001b[1minvokelatest\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:889\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [10] \u001b[0m\u001b[1mmaybe_cachefile_lock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mBase.var\"#971#972\"\u001b[90m{Base.PkgId}\u001b[39m, \u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90msrcpath\u001b[39m::\u001b[0mString; \u001b[90mstale_age\u001b[39m::\u001b[0mInt64\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:3054\u001b[24m\u001b[39m\n",
      " [11] \u001b[0m\u001b[1mmaybe_cachefile_lock\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:3051\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [12] \u001b[0m\u001b[1m_require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2040\u001b[24m\u001b[39m\n",
      " [13] \u001b[0m\u001b[1m__require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1882\u001b[24m\u001b[39m\n",
      " [14] \u001b[0m\u001b[1m#invoke_in_world#3\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:926\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [15] \u001b[0m\u001b[1minvoke_in_world\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:923\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [16] \u001b[0m\u001b[1m_require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1873\u001b[24m\u001b[39m\n",
      " [17] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1860\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [18] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlock.jl:267\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [19] \u001b[0m\u001b[1m__require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1823\u001b[24m\u001b[39m\n",
      " [20] \u001b[0m\u001b[1m#invoke_in_world#3\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:926\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [21] \u001b[0m\u001b[1minvoke_in_world\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:923\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [22] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1816\u001b[24m\u001b[39m\n",
      " [23] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90m_path\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:495\u001b[24m\u001b[39m\n",
      " [24] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[36mTreeParzen\u001b[39m \u001b[90mC:\\Users\\natal\\.julia\\packages\\TreeParzen\\BycQ1\\src\\\u001b[39m\u001b[90m\u001b[4mTreeParzen.jl:1\u001b[24m\u001b[39m\n",
      " [25] top-level scope\n",
      "\u001b[90m    @\u001b[39m \u001b[90mC:\\Users\\natal\\.julia\\packages\\TreeParzen\\BycQ1\\src\\\u001b[39m\u001b[90m\u001b[4mTreeParzen.jl:12\u001b[24m\u001b[39m\n",
      " [26] \u001b[0m\u001b[1minclude\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:495\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [27] \u001b[0m\u001b[1minclude_package_for_output\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90minput\u001b[39m::\u001b[0mString, \u001b[90mdepot_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mdl_load_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mload_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mconcrete_deps\u001b[39m::\u001b[0mVector\u001b[90m{Pair{Base.PkgId, UInt128}}\u001b[39m, \u001b[90msource\u001b[39m::\u001b[0mNothing\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2292\u001b[24m\u001b[39m\n",
      " [28] top-level scope\n",
      "\u001b[90m    @\u001b[39m \u001b[90m\u001b[4mstdin:4\u001b[24m\u001b[39m\n",
      "in expression starting at C:\\Users\\natal\\.julia\\packages\\TreeParzen\\BycQ1\\src\\Bincounts.jl:1\n",
      "in expression starting at C:\\Users\\natal\\.julia\\packages\\TreeParzen\\BycQ1\\src\\TreeParzen.jl:1\n",
      "in expression starting at stdin:4\n",
      "BayesianOptimization \n",
      "\n",
      "Failed to precompile BayesianOptimization [4c6ed407-134f-591c-93fa-e0f7c164a0ec] to \"C:\\\\Users\\\\natal\\\\.julia\\\\compiled\\\\v1.10\\\\BayesianOptimization\\\\jl_134D.tmp\".\n",
      "\u001b[91m\u001b[1mERROR: \u001b[22m\u001b[39mLoadError: SpecialFunctions is not installed properly, run `Pkg.build(\"SpecialFunctions\")`,restart Julia and try again\n",
      "Stacktrace:\n",
      " [1] \u001b[0m\u001b[1merror\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90ms\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4merror.jl:35\u001b[24m\u001b[39m\n",
      " [2] top-level scope\n",
      "\u001b[90m   @\u001b[39m \u001b[90mC:\\Users\\natal\\.julia\\packages\\SpecialFunctions\\ne2iw\\src\\\u001b[39m\u001b[90m\u001b[4mSpecialFunctions.jl:6\u001b[24m\u001b[39m\n",
      " [3] \u001b[0m\u001b[1minclude\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:495\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [4] \u001b[0m\u001b[1minclude_package_for_output\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90minput\u001b[39m::\u001b[0mString, \u001b[90mdepot_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mdl_load_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mload_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mconcrete_deps\u001b[39m::\u001b[0mVector\u001b[90m{Pair{Base.PkgId, UInt128}}\u001b[39m, \u001b[90msource\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2292\u001b[24m\u001b[39m\n",
      " [5] top-level scope\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mstdin:4\u001b[24m\u001b[39m\n",
      "in expression starting at C:\\Users\\natal\\.julia\\packages\\SpecialFunctions\\ne2iw\\src\\SpecialFunctions.jl:1\n",
      "in expression starting at stdin:4\n",
      "\u001b[91m\u001b[1mERROR: \u001b[22m\u001b[39mLoadError: Failed to precompile SpecialFunctions [276daf66-3868-5448-9aa4-cd146d93841b] to \"C:\\\\Users\\\\natal\\\\.julia\\\\compiled\\\\v1.10\\\\SpecialFunctions\\\\jl_4CFA.tmp\".\n",
      "Stacktrace:\n",
      "  [1] \u001b[0m\u001b[1merror\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90ms\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4merror.jl:35\u001b[24m\u001b[39m\n",
      "  [2] \u001b[0m\u001b[1mcompilecache\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90mpath\u001b[39m::\u001b[0mString, \u001b[90minternal_stderr\u001b[39m::\u001b[0mIO, \u001b[90minternal_stdout\u001b[39m::\u001b[0mIO, \u001b[90mkeep_loaded_modules\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2539\u001b[24m\u001b[39m\n",
      "  [3] \u001b[0m\u001b[1mcompilecache\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2411\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [4] \u001b[0m\u001b[1m(::Base.var\"#971#972\"{Base.PkgId})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2044\u001b[24m\u001b[39m\n",
      "  [5] \u001b[0m\u001b[1mmkpidlock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mBase.var\"#971#972\"\u001b[90m{Base.PkgId}\u001b[39m, \u001b[90mat\u001b[39m::\u001b[0mString, \u001b[90mpid\u001b[39m::\u001b[0mInt32; \u001b[90mkwopts\u001b[39m::\u001b[0m@Kwargs\u001b[90m{stale_age::Int64, wait::Bool}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mFileWatching.Pidfile\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:93\u001b[24m\u001b[39m\n",
      "  [6] \u001b[0m\u001b[1m#mkpidlock#6\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:88\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [7] \u001b[0m\u001b[1mtrymkpidlock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m::\u001b[0mFunction, ::\u001b[0mVararg\u001b[90m{Any}\u001b[39m; \u001b[90mkwargs\u001b[39m::\u001b[0m@Kwargs\u001b[90m{stale_age::Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mFileWatching.Pidfile\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:111\u001b[24m\u001b[39m\n",
      "  [8] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:894\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [9] \u001b[0m\u001b[1minvokelatest\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:889\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [10] \u001b[0m\u001b[1mmaybe_cachefile_lock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mBase.var\"#971#972\"\u001b[90m{Base.PkgId}\u001b[39m, \u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90msrcpath\u001b[39m::\u001b[0mString; \u001b[90mstale_age\u001b[39m::\u001b[0mInt64\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:3054\u001b[24m\u001b[39m\n",
      " [11] \u001b[0m\u001b[1mmaybe_cachefile_lock\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:3051\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [12] \u001b[0m\u001b[1m_require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2040\u001b[24m\u001b[39m\n",
      " [13] \u001b[0m\u001b[1m__require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1882\u001b[24m\u001b[39m\n",
      " [14] \u001b[0m\u001b[1m#invoke_in_world#3\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:926\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [15] \u001b[0m\u001b[1minvoke_in_world\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:923\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [16] \u001b[0m\u001b[1m_require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1873\u001b[24m\u001b[39m\n",
      " [17] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1860\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [18] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlock.jl:267\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [19] \u001b[0m\u001b[1m__require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1823\u001b[24m\u001b[39m\n",
      " [20] \u001b[0m\u001b[1m#invoke_in_world#3\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:926\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [21] \u001b[0m\u001b[1minvoke_in_world\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:923\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [22] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1816\u001b[24m\u001b[39m\n",
      " [23] \u001b[0m\u001b[1minclude\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:495\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [24] \u001b[0m\u001b[1minclude_package_for_output\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90minput\u001b[39m::\u001b[0mString, \u001b[90mdepot_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mdl_load_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mload_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mconcrete_deps\u001b[39m::\u001b[0mVector\u001b[90m{Pair{Base.PkgId, UInt128}}\u001b[39m, \u001b[90msource\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2292\u001b[24m\u001b[39m\n",
      " [25] top-level scope\n",
      "\u001b[90m    @\u001b[39m \u001b[90m\u001b[4mstdin:4\u001b[24m\u001b[39m\n",
      "in expression starting at C:\\Users\\natal\\.julia\\packages\\ForwardDiff\\UBbGT\\src\\ForwardDiff.jl:1\n",
      "in expression starting at stdin:4\n",
      "\u001b[91m\u001b[1mERROR: \u001b[22m\u001b[39mLoadError: Failed to precompile ForwardDiff [f6369f11-7733-5829-9624-2563aa707210] to \"C:\\\\Users\\\\natal\\\\.julia\\\\compiled\\\\v1.10\\\\ForwardDiff\\\\jl_4B83.tmp\".\n",
      "Stacktrace:\n",
      "  [1] \u001b[0m\u001b[1merror\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90ms\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4merror.jl:35\u001b[24m\u001b[39m\n",
      "  [2] \u001b[0m\u001b[1mcompilecache\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90mpath\u001b[39m::\u001b[0mString, \u001b[90minternal_stderr\u001b[39m::\u001b[0mIO, \u001b[90minternal_stdout\u001b[39m::\u001b[0mIO, \u001b[90mkeep_loaded_modules\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2539\u001b[24m\u001b[39m\n",
      "  [3] \u001b[0m\u001b[1mcompilecache\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2411\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [4] \u001b[0m\u001b[1m(::Base.var\"#971#972\"{Base.PkgId})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2044\u001b[24m\u001b[39m\n",
      "  [5] \u001b[0m\u001b[1mmkpidlock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mBase.var\"#971#972\"\u001b[90m{Base.PkgId}\u001b[39m, \u001b[90mat\u001b[39m::\u001b[0mString, \u001b[90mpid\u001b[39m::\u001b[0mInt32; \u001b[90mkwopts\u001b[39m::\u001b[0m@Kwargs\u001b[90m{stale_age::Int64, wait::Bool}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mFileWatching.Pidfile\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:93\u001b[24m\u001b[39m\n",
      "  [6] \u001b[0m\u001b[1m#mkpidlock#6\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:88\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [7] \u001b[0m\u001b[1mtrymkpidlock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m::\u001b[0mFunction, ::\u001b[0mVararg\u001b[90m{Any}\u001b[39m; \u001b[90mkwargs\u001b[39m::\u001b[0m@Kwargs\u001b[90m{stale_age::Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mFileWatching.Pidfile\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:111\u001b[24m\u001b[39m\n",
      "  [8] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:894\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [9] \u001b[0m\u001b[1minvokelatest\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:889\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [10] \u001b[0m\u001b[1mmaybe_cachefile_lock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mBase.var\"#971#972\"\u001b[90m{Base.PkgId}\u001b[39m, \u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90msrcpath\u001b[39m::\u001b[0mString; \u001b[90mstale_age\u001b[39m::\u001b[0mInt64\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:3054\u001b[24m\u001b[39m\n",
      " [11] \u001b[0m\u001b[1mmaybe_cachefile_lock\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:3051\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [12] \u001b[0m\u001b[1m_require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2040\u001b[24m\u001b[39m\n",
      " [13] \u001b[0m\u001b[1m__require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1882\u001b[24m\u001b[39m\n",
      " [14] \u001b[0m\u001b[1m#invoke_in_world#3\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:926\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [15] \u001b[0m\u001b[1minvoke_in_world\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:923\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [16] \u001b[0m\u001b[1m_require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1873\u001b[24m\u001b[39m\n",
      " [17] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1860\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [18] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlock.jl:267\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [19] \u001b[0m\u001b[1m__require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1823\u001b[24m\u001b[39m\n",
      " [20] \u001b[0m\u001b[1m#invoke_in_world#3\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:926\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [21] \u001b[0m\u001b[1minvoke_in_world\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:923\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [22] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1816\u001b[24m\u001b[39m\n",
      " [23] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90m_path\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:495\u001b[24m\u001b[39m\n",
      " [24] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[36mMathOptInterface\u001b[39m \u001b[90mC:\\Users\\natal\\.julia\\packages\\MathOptInterface\\ugDMh\\src\\\u001b[39m\u001b[90m\u001b[4mMathOptInterface.jl:7\u001b[24m\u001b[39m\n",
      " [25] top-level scope\n",
      "\u001b[90m    @\u001b[39m \u001b[90mC:\\Users\\natal\\.julia\\packages\\MathOptInterface\\ugDMh\\src\\\u001b[39m\u001b[90m\u001b[4mMathOptInterface.jl:439\u001b[24m\u001b[39m\n",
      " [26] \u001b[0m\u001b[1minclude\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:495\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [27] \u001b[0m\u001b[1minclude_package_for_output\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90minput\u001b[39m::\u001b[0mString, \u001b[90mdepot_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mdl_load_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mload_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mconcrete_deps\u001b[39m::\u001b[0mVector\u001b[90m{Pair{Base.PkgId, UInt128}}\u001b[39m, \u001b[90msource\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2292\u001b[24m\u001b[39m\n",
      " [28] top-level scope\n",
      "\u001b[90m    @\u001b[39m \u001b[90m\u001b[4mstdin:4\u001b[24m\u001b[39m\n",
      "in expression starting at C:\\Users\\natal\\.julia\\packages\\MathOptInterface\\ugDMh\\src\\Nonlinear\\Nonlinear.jl:7\n",
      "in expression starting at C:\\Users\\natal\\.julia\\packages\\MathOptInterface\\ugDMh\\src\\MathOptInterface.jl:7\n",
      "in expression starting at stdin:4\n",
      "\u001b[91m\u001b[1mERROR: \u001b[22m\u001b[39mLoadError: Failed to precompile MathOptInterface [b8f27783-ece8-5eb3-8dc8-9495eed66fee] to \"C:\\\\Users\\\\natal\\\\.julia\\\\compiled\\\\v1.10\\\\MathOptInterface\\\\jl_18DB.tmp\".\n",
      "Stacktrace:\n",
      "  [1] \u001b[0m\u001b[1merror\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90ms\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4merror.jl:35\u001b[24m\u001b[39m\n",
      "  [2] \u001b[0m\u001b[1mcompilecache\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90mpath\u001b[39m::\u001b[0mString, \u001b[90minternal_stderr\u001b[39m::\u001b[0mIO, \u001b[90minternal_stdout\u001b[39m::\u001b[0mIO, \u001b[90mkeep_loaded_modules\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2539\u001b[24m\u001b[39m\n",
      "  [3] \u001b[0m\u001b[1mcompilecache\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2411\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [4] \u001b[0m\u001b[1m(::Base.var\"#971#972\"{Base.PkgId})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2044\u001b[24m\u001b[39m\n",
      "  [5] \u001b[0m\u001b[1mmkpidlock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mBase.var\"#971#972\"\u001b[90m{Base.PkgId}\u001b[39m, \u001b[90mat\u001b[39m::\u001b[0mString, \u001b[90mpid\u001b[39m::\u001b[0mInt32; \u001b[90mkwopts\u001b[39m::\u001b[0m@Kwargs\u001b[90m{stale_age::Int64, wait::Bool}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mFileWatching.Pidfile\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:93\u001b[24m\u001b[39m\n",
      "  [6] \u001b[0m\u001b[1m#mkpidlock#6\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:88\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [7] \u001b[0m\u001b[1mtrymkpidlock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m::\u001b[0mFunction, ::\u001b[0mVararg\u001b[90m{Any}\u001b[39m; \u001b[90mkwargs\u001b[39m::\u001b[0m@Kwargs\u001b[90m{stale_age::Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mFileWatching.Pidfile\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:111\u001b[24m\u001b[39m\n",
      "  [8] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:894\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [9] \u001b[0m\u001b[1minvokelatest\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:889\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [10] \u001b[0m\u001b[1mmaybe_cachefile_lock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mBase.var\"#971#972\"\u001b[90m{Base.PkgId}\u001b[39m, \u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90msrcpath\u001b[39m::\u001b[0mString; \u001b[90mstale_age\u001b[39m::\u001b[0mInt64\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:3054\u001b[24m\u001b[39m\n",
      " [11] \u001b[0m\u001b[1mmaybe_cachefile_lock\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:3051\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [12] \u001b[0m\u001b[1m_require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2040\u001b[24m\u001b[39m\n",
      " [13] \u001b[0m\u001b[1m__require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1882\u001b[24m\u001b[39m\n",
      " [14] \u001b[0m\u001b[1m#invoke_in_world#3\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:926\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [15] \u001b[0m\u001b[1minvoke_in_world\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:923\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [16] \u001b[0m\u001b[1m_require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1873\u001b[24m\u001b[39m\n",
      " [17] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1860\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [18] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlock.jl:267\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [19] \u001b[0m\u001b[1m__require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1823\u001b[24m\u001b[39m\n",
      " [20] \u001b[0m\u001b[1m#invoke_in_world#3\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:926\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [21] \u001b[0m\u001b[1minvoke_in_world\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:923\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [22] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1816\u001b[24m\u001b[39m\n",
      " [23] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90m_path\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:495\u001b[24m\u001b[39m\n",
      " [24] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[36mNLopt\u001b[39m \u001b[90mC:\\Users\\natal\\.julia\\packages\\NLopt\\OIUOZ\\src\\\u001b[39m\u001b[90m\u001b[4mNLopt.jl:1\u001b[24m\u001b[39m\n",
      " [25] top-level scope\n",
      "\u001b[90m    @\u001b[39m \u001b[90mC:\\Users\\natal\\.julia\\packages\\NLopt\\OIUOZ\\src\\\u001b[39m\u001b[90m\u001b[4mNLopt.jl:630\u001b[24m\u001b[39m\n",
      " [26] \u001b[0m\u001b[1minclude\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:495\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [27] \u001b[0m\u001b[1minclude_package_for_output\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90minput\u001b[39m::\u001b[0mString, \u001b[90mdepot_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mdl_load_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mload_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mconcrete_deps\u001b[39m::\u001b[0mVector\u001b[90m{Pair{Base.PkgId, UInt128}}\u001b[39m, \u001b[90msource\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2292\u001b[24m\u001b[39m\n",
      " [28] top-level scope\n",
      "\u001b[90m    @\u001b[39m \u001b[90m\u001b[4mstdin:4\u001b[24m\u001b[39m\n",
      "in expression starting at C:\\Users\\natal\\.julia\\packages\\NLopt\\OIUOZ\\src\\MOI_wrapper.jl:1\n",
      "in expression starting at C:\\Users\\natal\\.julia\\packages\\NLopt\\OIUOZ\\src\\NLopt.jl:1\n",
      "in expression starting at stdin:4\n",
      "\u001b[91m\u001b[1mERROR: \u001b[22m\u001b[39mLoadError: Failed to precompile NLopt [76087f3c-5699-56af-9a33-bf431cd00edd] to \"C:\\\\Users\\\\natal\\\\.julia\\\\compiled\\\\v1.10\\\\NLopt\\\\jl_1456.tmp\".\n",
      "Stacktrace:\n",
      "  [1] \u001b[0m\u001b[1merror\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90ms\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4merror.jl:35\u001b[24m\u001b[39m\n",
      "  [2] \u001b[0m\u001b[1mcompilecache\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90mpath\u001b[39m::\u001b[0mString, \u001b[90minternal_stderr\u001b[39m::\u001b[0mIO, \u001b[90minternal_stdout\u001b[39m::\u001b[0mIO, \u001b[90mkeep_loaded_modules\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2539\u001b[24m\u001b[39m\n",
      "  [3] \u001b[0m\u001b[1mcompilecache\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2411\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [4] \u001b[0m\u001b[1m(::Base.var\"#971#972\"{Base.PkgId})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2044\u001b[24m\u001b[39m\n",
      "  [5] \u001b[0m\u001b[1mmkpidlock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mBase.var\"#971#972\"\u001b[90m{Base.PkgId}\u001b[39m, \u001b[90mat\u001b[39m::\u001b[0mString, \u001b[90mpid\u001b[39m::\u001b[0mInt32; \u001b[90mkwopts\u001b[39m::\u001b[0m@Kwargs\u001b[90m{stale_age::Int64, wait::Bool}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mFileWatching.Pidfile\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:93\u001b[24m\u001b[39m\n",
      "  [6] \u001b[0m\u001b[1m#mkpidlock#6\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:88\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [7] \u001b[0m\u001b[1mtrymkpidlock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m::\u001b[0mFunction, ::\u001b[0mVararg\u001b[90m{Any}\u001b[39m; \u001b[90mkwargs\u001b[39m::\u001b[0m@Kwargs\u001b[90m{stale_age::Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mFileWatching.Pidfile\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:111\u001b[24m\u001b[39m\n",
      "  [8] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:894\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [9] \u001b[0m\u001b[1minvokelatest\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:889\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [10] \u001b[0m\u001b[1mmaybe_cachefile_lock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mBase.var\"#971#972\"\u001b[90m{Base.PkgId}\u001b[39m, \u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90msrcpath\u001b[39m::\u001b[0mString; \u001b[90mstale_age\u001b[39m::\u001b[0mInt64\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:3054\u001b[24m\u001b[39m\n",
      " [11] \u001b[0m\u001b[1mmaybe_cachefile_lock\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:3051\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [12] \u001b[0m\u001b[1m_require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2040\u001b[24m\u001b[39m\n",
      " [13] \u001b[0m\u001b[1m__require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1882\u001b[24m\u001b[39m\n",
      " [14] \u001b[0m\u001b[1m#invoke_in_world#3\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:926\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [15] \u001b[0m\u001b[1minvoke_in_world\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:923\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [16] \u001b[0m\u001b[1m_require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1873\u001b[24m\u001b[39m\n",
      " [17] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1860\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [18] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlock.jl:267\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [19] \u001b[0m\u001b[1m__require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1823\u001b[24m\u001b[39m\n",
      " [20] \u001b[0m\u001b[1m#invoke_in_world#3\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:926\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [21] \u001b[0m\u001b[1minvoke_in_world\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:923\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [22] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1816\u001b[24m\u001b[39m\n",
      " [23] \u001b[0m\u001b[1minclude\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:495\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [24] \u001b[0m\u001b[1minclude_package_for_output\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90minput\u001b[39m::\u001b[0mString, \u001b[90mdepot_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mdl_load_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mload_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mconcrete_deps\u001b[39m::\u001b[0mVector\u001b[90m{Pair{Base.PkgId, UInt128}}\u001b[39m, \u001b[90msource\u001b[39m::\u001b[0mNothing\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2292\u001b[24m\u001b[39m\n",
      " [25] top-level scope\n",
      "\u001b[90m    @\u001b[39m \u001b[90m\u001b[4mstdin:4\u001b[24m\u001b[39m\n",
      "in expression starting at C:\\Users\\natal\\.julia\\packages\\BayesianOptimization\\nq1HY\\src\\BayesianOptimization.jl:1\n",
      "in expression starting at stdin:4\n",
      "\n",
      "Distributions \n",
      "\n",
      "Failed to precompile Distributions [31c24e10-a181-5473-b8eb-7969acd0382f] to \"C:\\\\Users\\\\natal\\\\.julia\\\\compiled\\\\v1.10\\\\Distributions\\\\jl_7EB2.tmp\".\n",
      "\u001b[91m\u001b[1mERROR: \u001b[22m\u001b[39mLoadError: SpecialFunctions is not installed properly, run `Pkg.build(\"SpecialFunctions\")`,restart Julia and try again\n",
      "Stacktrace:\n",
      " [1] \u001b[0m\u001b[1merror\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90ms\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4merror.jl:35\u001b[24m\u001b[39m\n",
      " [2] top-level scope\n",
      "\u001b[90m   @\u001b[39m \u001b[90mC:\\Users\\natal\\.julia\\packages\\SpecialFunctions\\ne2iw\\src\\\u001b[39m\u001b[90m\u001b[4mSpecialFunctions.jl:6\u001b[24m\u001b[39m\n",
      " [3] \u001b[0m\u001b[1minclude\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:495\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [4] \u001b[0m\u001b[1minclude_package_for_output\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90minput\u001b[39m::\u001b[0mString, \u001b[90mdepot_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mdl_load_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mload_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mconcrete_deps\u001b[39m::\u001b[0mVector\u001b[90m{Pair{Base.PkgId, UInt128}}\u001b[39m, \u001b[90msource\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2292\u001b[24m\u001b[39m\n",
      " [5] top-level scope\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mstdin:4\u001b[24m\u001b[39m\n",
      "in expression starting at C:\\Users\\natal\\.julia\\packages\\SpecialFunctions\\ne2iw\\src\\SpecialFunctions.jl:1\n",
      "in expression starting at stdin:4\n",
      "\u001b[91m\u001b[1mERROR: \u001b[22m\u001b[39mLoadError: Failed to precompile SpecialFunctions [276daf66-3868-5448-9aa4-cd146d93841b] to \"C:\\\\Users\\\\natal\\\\.julia\\\\compiled\\\\v1.10\\\\SpecialFunctions\\\\jl_87B6.tmp\".\n",
      "Stacktrace:\n",
      "  [1] \u001b[0m\u001b[1merror\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90ms\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4merror.jl:35\u001b[24m\u001b[39m\n",
      "  [2] \u001b[0m\u001b[1mcompilecache\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90mpath\u001b[39m::\u001b[0mString, \u001b[90minternal_stderr\u001b[39m::\u001b[0mIO, \u001b[90minternal_stdout\u001b[39m::\u001b[0mIO, \u001b[90mkeep_loaded_modules\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2539\u001b[24m\u001b[39m\n",
      "  [3] \u001b[0m\u001b[1mcompilecache\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2411\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [4] \u001b[0m\u001b[1m(::Base.var\"#971#972\"{Base.PkgId})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2044\u001b[24m\u001b[39m\n",
      "  [5] \u001b[0m\u001b[1mmkpidlock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mBase.var\"#971#972\"\u001b[90m{Base.PkgId}\u001b[39m, \u001b[90mat\u001b[39m::\u001b[0mString, \u001b[90mpid\u001b[39m::\u001b[0mInt32; \u001b[90mkwopts\u001b[39m::\u001b[0m@Kwargs\u001b[90m{stale_age::Int64, wait::Bool}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mFileWatching.Pidfile\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:93\u001b[24m\u001b[39m\n",
      "  [6] \u001b[0m\u001b[1m#mkpidlock#6\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:88\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [7] \u001b[0m\u001b[1mtrymkpidlock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m::\u001b[0mFunction, ::\u001b[0mVararg\u001b[90m{Any}\u001b[39m; \u001b[90mkwargs\u001b[39m::\u001b[0m@Kwargs\u001b[90m{stale_age::Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mFileWatching.Pidfile\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:111\u001b[24m\u001b[39m\n",
      "  [8] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:894\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [9] \u001b[0m\u001b[1minvokelatest\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:889\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [10] \u001b[0m\u001b[1mmaybe_cachefile_lock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mBase.var\"#971#972\"\u001b[90m{Base.PkgId}\u001b[39m, \u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90msrcpath\u001b[39m::\u001b[0mString; \u001b[90mstale_age\u001b[39m::\u001b[0mInt64\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:3054\u001b[24m\u001b[39m\n",
      " [11] \u001b[0m\u001b[1mmaybe_cachefile_lock\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:3051\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [12] \u001b[0m\u001b[1m_require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2040\u001b[24m\u001b[39m\n",
      " [13] \u001b[0m\u001b[1m__require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1882\u001b[24m\u001b[39m\n",
      " [14] \u001b[0m\u001b[1m#invoke_in_world#3\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:926\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [15] \u001b[0m\u001b[1minvoke_in_world\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:923\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [16] \u001b[0m\u001b[1m_require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1873\u001b[24m\u001b[39m\n",
      " [17] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1860\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [18] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlock.jl:267\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [19] \u001b[0m\u001b[1m__require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1823\u001b[24m\u001b[39m\n",
      " [20] \u001b[0m\u001b[1m#invoke_in_world#3\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:926\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [21] \u001b[0m\u001b[1minvoke_in_world\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:923\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [22] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1816\u001b[24m\u001b[39m\n",
      " [23] \u001b[0m\u001b[1minclude\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:495\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [24] \u001b[0m\u001b[1minclude_package_for_output\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90minput\u001b[39m::\u001b[0mString, \u001b[90mdepot_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mdl_load_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mload_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mconcrete_deps\u001b[39m::\u001b[0mVector\u001b[90m{Pair{Base.PkgId, UInt128}}\u001b[39m, \u001b[90msource\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2292\u001b[24m\u001b[39m\n",
      " [25] top-level scope\n",
      "\u001b[90m    @\u001b[39m \u001b[90m\u001b[4mstdin:4\u001b[24m\u001b[39m\n",
      "in expression starting at C:\\Users\\natal\\.julia\\packages\\StatsFuns\\P7Mci\\src\\StatsFuns.jl:3\n",
      "in expression starting at stdin:4\n",
      "\u001b[91m\u001b[1mERROR: \u001b[22m\u001b[39mLoadError: Failed to precompile StatsFuns [4c63d2b9-4356-54db-8cca-17b64c39e42c] to \"C:\\\\Users\\\\natal\\\\.julia\\\\compiled\\\\v1.10\\\\StatsFuns\\\\jl_816D.tmp\".\n",
      "Stacktrace:\n",
      "  [1] \u001b[0m\u001b[1merror\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90ms\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4merror.jl:35\u001b[24m\u001b[39m\n",
      "  [2] \u001b[0m\u001b[1mcompilecache\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90mpath\u001b[39m::\u001b[0mString, \u001b[90minternal_stderr\u001b[39m::\u001b[0mIO, \u001b[90minternal_stdout\u001b[39m::\u001b[0mIO, \u001b[90mkeep_loaded_modules\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2539\u001b[24m\u001b[39m\n",
      "  [3] \u001b[0m\u001b[1mcompilecache\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2411\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [4] \u001b[0m\u001b[1m(::Base.var\"#971#972\"{Base.PkgId})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2044\u001b[24m\u001b[39m\n",
      "  [5] \u001b[0m\u001b[1mmkpidlock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mBase.var\"#971#972\"\u001b[90m{Base.PkgId}\u001b[39m, \u001b[90mat\u001b[39m::\u001b[0mString, \u001b[90mpid\u001b[39m::\u001b[0mInt32; \u001b[90mkwopts\u001b[39m::\u001b[0m@Kwargs\u001b[90m{stale_age::Int64, wait::Bool}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mFileWatching.Pidfile\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:93\u001b[24m\u001b[39m\n",
      "  [6] \u001b[0m\u001b[1m#mkpidlock#6\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:88\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [7] \u001b[0m\u001b[1mtrymkpidlock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m::\u001b[0mFunction, ::\u001b[0mVararg\u001b[90m{Any}\u001b[39m; \u001b[90mkwargs\u001b[39m::\u001b[0m@Kwargs\u001b[90m{stale_age::Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mFileWatching.Pidfile\u001b[39m \u001b[90mC:\\Users\\natal\\AppData\\Local\\Programs\\Julia-1.10.10\\share\\julia\\stdlib\\v1.10\\FileWatching\\src\\\u001b[39m\u001b[90m\u001b[4mpidfile.jl:111\u001b[24m\u001b[39m\n",
      "  [8] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:894\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [9] \u001b[0m\u001b[1minvokelatest\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:889\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [10] \u001b[0m\u001b[1mmaybe_cachefile_lock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mBase.var\"#971#972\"\u001b[90m{Base.PkgId}\u001b[39m, \u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90msrcpath\u001b[39m::\u001b[0mString; \u001b[90mstale_age\u001b[39m::\u001b[0mInt64\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:3054\u001b[24m\u001b[39m\n",
      " [11] \u001b[0m\u001b[1mmaybe_cachefile_lock\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:3051\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [12] \u001b[0m\u001b[1m_require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2040\u001b[24m\u001b[39m\n",
      " [13] \u001b[0m\u001b[1m__require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1882\u001b[24m\u001b[39m\n",
      " [14] \u001b[0m\u001b[1m#invoke_in_world#3\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:926\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [15] \u001b[0m\u001b[1minvoke_in_world\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:923\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [16] \u001b[0m\u001b[1m_require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1873\u001b[24m\u001b[39m\n",
      " [17] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1860\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [18] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlock.jl:267\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [19] \u001b[0m\u001b[1m__require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1823\u001b[24m\u001b[39m\n",
      " [20] \u001b[0m\u001b[1m#invoke_in_world#3\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:926\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [21] \u001b[0m\u001b[1minvoke_in_world\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:923\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [22] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1816\u001b[24m\u001b[39m\n",
      " [23] \u001b[0m\u001b[1minclude\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:495\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [24] \u001b[0m\u001b[1minclude_package_for_output\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90minput\u001b[39m::\u001b[0mString, \u001b[90mdepot_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mdl_load_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mload_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mconcrete_deps\u001b[39m::\u001b[0mVector\u001b[90m{Pair{Base.PkgId, UInt128}}\u001b[39m, \u001b[90msource\u001b[39m::\u001b[0mNothing\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2292\u001b[24m\u001b[39m\n",
      " [25] top-level scope\n",
      "\u001b[90m    @\u001b[39m \u001b[90m\u001b[4mstdin:4\u001b[24m\u001b[39m\n",
      "in expression starting at C:\\Users\\natal\\.julia\\packages\\Distributions\\9Albf\\src\\Distributions.jl:1\n",
      "in expression starting at stdin:4"
     ]
    }
   ],
   "source": [
    "#Pkg.add(\"TreeParzen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7bfa8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(DeterministicTunedModel(model = LGBMRegressor(objective = regression, …), …), …).\n",
      "└ @ MLJBase C:\\Users\\natal\\.julia\\packages\\MLJBase\\7nGJF\\src\\machines.jl:499\n",
      "┌ Info: Attempting to evaluate 25 models.\n",
      "└ @ MLJTuning C:\\Users\\natal\\.julia\\packages\\MLJTuning\\vMe8s\\src\\tuned_models.jl:762\n",
      "\u001b[33mEvaluating over 20 metamodels:  10%[==>                      ]  ETA: 0:04:47\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016996 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 20 metamodels:  15%[===>                     ]  ETA: 0:04:33\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 20 metamodels:  20%[=====>                   ]  ETA: 0:05:08\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 20 metamodels:  25%[======>                  ]  ETA: 0:06:15\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014014 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 20 metamodels:  30%[=======>                 ]  ETA: 0:06:04\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 20 metamodels:  35%[========>                ]  ETA: 0:06:17\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012985 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 20 metamodels:  40%[==========>              ]  ETA: 0:05:27\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 20 metamodels:  45%[===========>             ]  ETA: 0:05:14\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007838 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013993 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 20 metamodels:  50%[============>            ]  ETA: 0:04:48\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 20 metamodels:  55%[=============>           ]  ETA: 0:04:25\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 20 metamodels:  60%[===============>         ]  ETA: 0:03:51\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013980 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016987 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 20 metamodels:  65%[================>        ]  ETA: 0:03:26\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 20 metamodels:  70%[=================>       ]  ETA: 0:03:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012957 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 20 metamodels:  75%[==================>      ]  ETA: 0:02:26\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006946 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 20 metamodels:  80%[====================>    ]  ETA: 0:01:51\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 20 metamodels:  85%[=====================>   ]  ETA: 0:01:21\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 20 metamodels:  90%[======================>  ]  ETA: 0:00:56\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 20 metamodels:  95%[=======================> ]  ETA: 0:00:29\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 20 metamodels: 100%[=========================] Time: 0:10:09\u001b[39m\u001b[K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007824 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1848\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1835\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.226000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1844\n",
      "[LightGBM] [Info] Number of data points in the train set: 221199, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.225996\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1841\n",
      "[LightGBM] [Info] Number of data points in the train set: 221200, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.230773\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1837\n",
      "[LightGBM] [Info] Number of data points in the train set: 276499, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 1.227494\n",
      "Mejores hiperparámetros bayesianos para LGBM:\n",
      "LGBMRegressor(objective = regression, …)\n",
      "\n",
      "Métricas en test:\n",
      " RMSE = 1.6128\n",
      " MAE  = 0.6042\n"
     ]
    }
   ],
   "source": [
    "using MLJ\n",
    "using MLJTuning\n",
    "using TreeParzen: HP, MLJTreeParzenTuning\n",
    "using MLJ: @load, machine, fit!, predict, CV, rms\n",
    "using LightGBM; import LightGBM.MLJInterface: LGBMRegressor\n",
    "# ——————————————\n",
    "# 6. TUNING “BAYESIANO” PARA LIGHTGBM\n",
    "# ——————————————\n",
    "\n",
    "# 6.1. Asegúrate de tener instalado TreeParzen.jl:\n",
    "# ] add TreeParzen\n",
    "\n",
    "@load LGBMRegressor pkg=LightGBM verbosity=0\n",
    "\n",
    "# 6.2. Definir modelo base y rangos de búsqueda\n",
    "lgbm = LGBMRegressor()\n",
    "\n",
    "# 2. Define el espacio de búsqueda usando HP.*\n",
    "space = Dict(\n",
    "  :num_iterations => HP.QuantUniform(:num_iterations, 50., 300., 1.),\n",
    "  :learning_rate  => HP.Uniform(:learning_rate, 0.01, 0.2),\n",
    "  :num_leaves     => HP.QuantUniform(:num_leaves,      10., 100., 1.)\n",
    ")\n",
    "\n",
    "#ranges = [\n",
    "#    range(lgbm, :num_iterations, lower=50,  upper=300),\n",
    "#    range(lgbm, :learning_rate,   lower=0.01, upper=0.2),\n",
    "#    range(lgbm, :num_leaves,      lower=10,   upper=100),\n",
    "#]\n",
    "\n",
    "# 6.3. Configurar TunedModel con Tree-Parzen (bayesiano)\n",
    "tuner = TunedModel(\n",
    "  model       = lgbm,\n",
    "  range       = space,                       # <- ojo: range=, no ranges=\n",
    "  tuning      = MLJTreeParzenTuning(),       # estrategia TPE\n",
    "  resampling  = CV(nfolds=5, shuffle=true),\n",
    "  measure     = rms,\n",
    "  n           = 25,                          # iteraciones totales\n",
    "  acceleration= CPUThreads()\n",
    ")\n",
    "\n",
    "# 1) Entrena el tuner\n",
    "tmach = machine(tuner, X_train_fixed, y_train_fixed)\n",
    "fit!(tmach, verbosity=1)            # → que llegue a completarse sin errores\n",
    "\n",
    "# 2) Extrae los mejores hiperparámetros\n",
    "best_lgbm = fitted_params(tmach).best_model\n",
    "println(\"Mejores hiperparámetros bayesianos para LGBM:\")\n",
    "println(best_lgbm)\n",
    "\n",
    "# 3) Predice sobre el test set\n",
    "ŷ = predict(tmach, X_test_fixed) |> collect\n",
    "\n",
    "# 4) Calcula RMSE y MAE\n",
    "rmse = sqrt(mean((ŷ .- y_test_fixed).^2))\n",
    "mae  = mean(abs.(ŷ .- y_test_fixed))\n",
    "\n",
    "println(\"\\nMétricas en test:\")\n",
    "println(\" RMSE = \", round(rmse, digits=4))\n",
    "println(\" MAE  = \", round(mae,  digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbf34fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>10×3 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Feature</th><th style = \"text-align: left;\">Coefficient</th><th style = \"text-align: left;\">Importance_Rank</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">sales_rolling_3</td><td style = \"text-align: right;\">0.860157</td><td style = \"text-align: right;\">40</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">sales_rolling_7</td><td style = \"text-align: right;\">0.199064</td><td style = \"text-align: right;\">22</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">sales_lag_1</td><td style = \"text-align: right;\">0.182801</td><td style = \"text-align: right;\">13</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">sales_rolling_30</td><td style = \"text-align: right;\">0.077704</td><td style = \"text-align: right;\">7</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">DayOfWeek</td><td style = \"text-align: right;\">0.0490341</td><td style = \"text-align: right;\">28</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">product_sales_mean</td><td style = \"text-align: right;\">0.0356142</td><td style = \"text-align: right;\">19</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">DayOfWeek_sin</td><td style = \"text-align: right;\">0.0211705</td><td style = \"text-align: right;\">20</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">DayOfWeek_cos</td><td style = \"text-align: right;\">0.0157785</td><td style = \"text-align: right;\">12</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">IsWeekend</td><td style = \"text-align: right;\">0.0157271</td><td style = \"text-align: right;\">9</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: left;\">WeekOfYear</td><td style = \"text-align: right;\">0.0143109</td><td style = \"text-align: right;\">10</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& Feature & Coefficient & Importance\\_Rank\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & sales\\_rolling\\_3 & 0.860157 & 40 \\\\\n",
       "\t2 & sales\\_rolling\\_7 & 0.199064 & 22 \\\\\n",
       "\t3 & sales\\_lag\\_1 & 0.182801 & 13 \\\\\n",
       "\t4 & sales\\_rolling\\_30 & 0.077704 & 7 \\\\\n",
       "\t5 & DayOfWeek & 0.0490341 & 28 \\\\\n",
       "\t6 & product\\_sales\\_mean & 0.0356142 & 19 \\\\\n",
       "\t7 & DayOfWeek\\_sin & 0.0211705 & 20 \\\\\n",
       "\t8 & DayOfWeek\\_cos & 0.0157785 & 12 \\\\\n",
       "\t9 & IsWeekend & 0.0157271 & 9 \\\\\n",
       "\t10 & WeekOfYear & 0.0143109 & 10 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m10×3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Feature            \u001b[0m\u001b[1m Coefficient \u001b[0m\u001b[1m Importance_Rank \u001b[0m\n",
       "     │\u001b[90m String             \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Int64           \u001b[0m\n",
       "─────┼──────────────────────────────────────────────────\n",
       "   1 │ sales_rolling_3       0.860157                40\n",
       "   2 │ sales_rolling_7       0.199064                22\n",
       "   3 │ sales_lag_1           0.182801                13\n",
       "   4 │ sales_rolling_30      0.077704                 7\n",
       "   5 │ DayOfWeek             0.0490341               28\n",
       "   6 │ product_sales_mean    0.0356142               19\n",
       "   7 │ DayOfWeek_sin         0.0211705               20\n",
       "   8 │ DayOfWeek_cos         0.0157785               12\n",
       "   9 │ IsWeekend             0.0157271                9\n",
       "  10 │ WeekOfYear            0.0143109               10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using MLJ, DataFrames\n",
    "\n",
    "# Entrenar Ridge\n",
    "model_ridge = RidgeRegressor(lambda=1.0)\n",
    "mach_ridge  = machine(model_ridge, X_train_fixed, y_train_fixed)\n",
    "fit!(mach_ridge, verbosity=0)\n",
    "\n",
    "# Obtener pares (feature => coef)\n",
    "coef_pairs = fitted_params(mach_ridge).coefs\n",
    "\n",
    "# Extraer nombres y valores absolutos\n",
    "features = String[]\n",
    "coefs    = Float64[]\n",
    "for (feat,coef) in coef_pairs\n",
    "    push!(features, string(feat))\n",
    "    push!(coefs, abs(coef))\n",
    "end\n",
    "\n",
    "# Calcular ranking de importancia\n",
    "ranks = sortperm(coefs, rev=true)\n",
    "\n",
    "# Crear DataFrame\n",
    "feature_importance = DataFrame(\n",
    "    Feature         = features,\n",
    "    Coefficient     = coefs,\n",
    "    Importance_Rank = ranks\n",
    ")\n",
    "\n",
    "# Mostrar top 10 por coeficiente\n",
    "first(sort(feature_importance, :Coefficient, rev=true), 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5552ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pkg.add(\"MLJLightGBMInterface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fddec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLJ\n",
    "using LightGBM, DataFrames\n",
    "\n",
    "# Importar explícitamente\n",
    "const LGBMRegressor = LightGBM.MLJInterface.LGBMRegressor\n",
    "\n",
    "model = LGBMRegressor(\n",
    "    objective = \"regression\",\n",
    "    learning_rate = 0.1,\n",
    "    num_iterations = 100,\n",
    "    num_leaves = 31,\n",
    "    metric = [\"l2\"] # 👈 CORREGIDO: vector de string\n",
    ")\n",
    "\n",
    "#X = MLJ.table(X_train_fixed)\n",
    "y = y_train_vector\n",
    "\n",
    "#mach = machine(model, X, y)\n",
    "\n",
    "mach = machine(model, X_train_fixed, y)\n",
    "\n",
    "fit!(mach)\n",
    "\n",
    "X_test_df = DataFrame(X_test_matrix, names(X_train_fixed))\n",
    "\n",
    "ŷ_native = predict(mach, MLJ.table(X_test_df)) |> collect\n",
    "\n",
    "mae_native = mean(abs.(ŷ_native .- y_test_vector))\n",
    "r2_native = 1 - sum((y_test_vector .- ŷ_native).^2) / sum((y_test_vector .- mean(y_test_vector)).^2)\n",
    "\n",
    "(\"LightGBM_MLJ\", \"SUCCESS\", mae_native, r2_native)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160ac29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "# Pkg.status()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.10",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
